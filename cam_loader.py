# THIS ğŸ“· by SWCC Corporation, GPL-3.0 license
"""
usage :
    dataset = LoadV4TISCams(source, img_size=640, stride=32, auto=True)
"""

import os, sys
import time
from threading import Thread
import re
import cv2
import numpy as np
import warnings
warnings.filterwarnings("ignore") # Warning will make operation confuse!!!

def clean_str(s):
    # Cleans a string by replacing special characters with underscore _
    return re.sub(pattern="[|@#!Â¡Â·$â‚¬%&()=?Â¿^*;:,Â¨Â´><+]", repl="_", string=s)

def letterbox(
    im,
    new_shape=(640, 640),
    color=(114, 114, 114),
    scaleup=True,
    stride=32,
):
    shape = im.shape[:2]  # current shape [height, width]

    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])
    if not scaleup:  # only scale down, do not scale up (for better val mAP)
        r = min(r, 1.0)

    ratio = r, r  # width, height ratios
    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))
    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding

    dw /= 2
    dh /= 2

    if shape[::-1] != new_unpad:  # resize
        im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)
    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))
    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))
    im = cv2.copyMakeBorder(
        im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color
    )
    return im, ratio, (dw, dh)

class LoadT4TISCams:
    # Tile
    def __init__(self, sources='4TISCams.txt', img_size=640, stride=32, auto=True):
        self.mode = 'stream'
        self.img_size = img_size
        self.stride = stride
        self.flag = True
        self.rbt_flag = False # ãƒ‡ãƒã‚¤ã‚¹ãƒ­ã‚¹ãƒˆãªã©ã§è‡ªå‹•çš„ã«è‡ªåˆ†ã‚’æ­¢ã‚ã‚‹ï¼ˆå†èµ·å‹•è¦å¦ã®ç›®å°ï¼‰ãƒ•ãƒ©ã‚°
        self.bubun = 40 # å‰ã¨æ–°ã—ã„ç”»åƒã®æ¯”è¼ƒã«ä½¿ã†å››è§’å½¢éƒ¨åˆ†ã®ä¸€è¾ºã®ãƒ”ã‚¯ã‚»ãƒ«æ•° â˜…å¿…ãšå¶æ•°ã«ã™ã‚‹ã“ã¨ï¼ï¼ï¼
        self.bad_cam = "" # ãƒ‡ãƒã‚¤ã‚¹ãƒ­ã‚¹ãƒˆã—ãŸã‚«ãƒ¡ãƒ©ã®ä½ç½®æƒ…å ±ã‚’æ¸¡ã™å¤‰æ•°

        if os.path.isfile(sources):
            with open(sources) as f:
                sources = [x.strip() for x in f.read().strip().splitlines() if len(x.strip()) and x[0] != '#']
        else:
            sources = [sources]

        print(sources)
        n = len(sources)
        try:
            # TISã‚«ãƒ¡ãƒ©ã®ãŸã‚ã«importã™ã‚‹
            import ctypes
            import tisgrabber as tis
        except:
            print('tisgrabber is not installed. Please check !')
            sys.exit(0)
        self.imgs, self.frames, self.threads = [None] * 4, [0] * n, [None] * n
        self.sources = [clean_str(x) for x in sources]  # clean source names for later
        self.auto = auto

        self.cnt = 0 # maenoã¨nowã®åŒä¸€ç”»åƒæ¤œå‡ºã®å›æ•°ã‚«ã‚¦ãƒ³ã‚¿
        self.maeno = [None] * 4 # æ¯”è¼ƒç”¨ç”»åƒã‚’ä¿å­˜ã™ã‚‹å¤‰æ•°
        self.now = [None] * 4
        for i in range(4): # åˆã‚ã«ç”»åƒæ¯”è¼ƒç”¨ã®å‰ã®ç”»åƒã«å½“ãŸã‚‹ã‚‚ã®ã‚’ç”¨æ„ã—ã¦ãŠã
            self.maeno[i] = np.full((self.bubun, self.bubun, 3), (0, 255, 0), dtype=np.uint8)        

        self.fps = 70
        self.w = 640
        self.h = 480 # temporary definition
        vformat = "RGB24 ({0}x{1})".format(self.w, self.h) # ã‚«ãƒ¡ãƒ©ã®ãƒ“ãƒ‡ã‚ªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’æŒ‡å®šã™ã‚‹å®šæ•°
        
        ic = ctypes.cdll.LoadLibrary("./tisgrabber_x64.dll") # TISãŠã¾ã˜ãªã„1
        tis.declareFunctions(ic) # TISãŠã¾ã˜ãªã„2
        ic.IC_InitLibrary(0) # TISãŠã¾ã˜ãªã„3
        hGrabber = [None] * 4 # ã‚«ãƒ¡ãƒ©ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆã‚’å®šç¾©ã—ã¦ãŠã
        # ã‚«ãƒ¡ãƒ©ã®ç«‹ä¸Šã‚Šé †ã«ã‚ˆã‚‹ã‚¨ãƒ©ãƒ¼ã‚’å›é¿ã™ã‚‹ãŸã‚ã«äºˆã‚èµ¤è‰²ã®ç”»é¢ã‚’ã‚«ãƒ¡ãƒ©ã®æ•°ã ã‘ç”¨æ„ã—ã¦ãŠã
        for i in range(4):  # index, source
            self.imgs[i] = np.full((self.h, self.w, 3), (0, 0, 255), dtype=np.uint8)

        for i, s in enumerate(sources):  # index, source
            self.imgs[i] = np.full((self.h, self.w, 3), (128, 128, 128), dtype=np.uint8) # ãƒ€ãƒŸãƒ¼ã¨ã—ã¦æœ€åˆã«ç°è‰²ç”»é¢ã‚’ç”¨æ„
            self.frames[i] = float('inf')  # infinite stream fallback
            # Start thread to read frames from video stream
            st = f'{i + 1}/{n}: {s}... '
            s = str(s)
            hGrabber[i] = ic.IC_CreateGrabber()
            ic.IC_OpenDevByUniqueName(hGrabber[i], tis.T(s)) # ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼ã®æŒ‡å®šã‚‚å¯èƒ½
            ic.IC_SetVideoFormat(hGrabber[i], tis.T(vformat))
            if (ic.IC_IsDevValid(hGrabber[i])): # ã‚«ãƒ¡ãƒ©ãŒé–‹ã‘ãŸã‚‰
                # å€‹åˆ¥ã«è¨­å®šã™ã‚‹ãªã‚‰ã“ã“ã§åˆ†å²ã‹ï¼Ÿ
                # ã‚«ãƒ¡ãƒ©ã®éœ²å…‰æ™‚é–“ã€FPSã€ãƒ›ãƒ¯ã‚¤ãƒˆãƒãƒ©ãƒ³ã‚¹ã€ã‚²ã‚¤ãƒ³ãªã©ã‚’è¨­å®šã™ã‚‹ 
                # fps: - 549 ã¨ Exposure ï¼š0.000001 - 30.0              
                ic.IC_SetFrameRate(hGrabber[i], ctypes.c_float(self.fps))
                ic.IC_SetPropertySwitch(hGrabber[i], tis.T("Exposure"), tis.T("Auto"), 0)
                ic.IC_SetPropertyAbsoluteValue(hGrabber[i], tis.T("Exposure"), tis.T("Value"), ctypes.c_float(0.004))
                #Brightness : 0 - 4095 Default 240
                ic.IC_SetPropertyValue(hGrabber[i], tis.T("Brightness"), tis.T("Value"),ctypes.c_int(240))
                #Gain :0.0 - 48.0 Default 1.0
                ic.IC_SetPropertySwitch(hGrabber[i], tis.T("Gain"), tis.T("Auto"), 0)
                ic.IC_SetPropertyAbsoluteValue(hGrabber[i], tis.T("Gain"), tis.T("Value"), ctypes.c_float(10.0))
                #WhiteBalance ï¼š å„è‰² 0.0 - 3.984375 â€»IC Captureãªã©ã§å®Ÿå†™ã‚’è¦‹ã¦èª¿æ•´
                ic.IC_SetPropertySwitch(hGrabber[i], tis.T("WhiteBalance"), tis.T("Auto"), 0)
                ic.IC_SetPropertyAbsoluteValue(hGrabber[i], tis.T("WhiteBalance"), tis.T("White Balance Red"), ctypes.c_float(1.66))
                ic.IC_SetPropertyAbsoluteValue(hGrabber[i], tis.T("WhiteBalance"), tis.T("White Balance Green"), ctypes.c_float(1.00))              
                ic.IC_SetPropertyAbsoluteValue(hGrabber[i], tis.T("WhiteBalance"), tis.T("White Balance Blue"), ctypes.c_float(2.48))
                # ã“ã“ã¾ã§ã§ã‚«ãƒ¡ãƒ©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šã¯çµ‚äº†
                
                # Start the live video stream, but show no own live video window. We will use OpenCV for this.
                ic.IC_StartLive(hGrabber[i], 0) # å¼•æ•°ã‚’ã€Œï¼‘ã€ã«ã™ã‚‹ã¨ãƒ©ã‚¤ãƒ–ç”»åƒãŒé–‹ãã€‚OpenCVã§ã®æç”»ã‚’ã™ã‚‹ã®ã§ã€Œï¼ã€ã¨ã™ã‚‹ã€‚
                #print('â˜…â˜…ic.IC_SnapImage(hGrabber[',i, ']: ', ic.IC_SnapImage(hGrabber[i])) #debugprint

                # é€£ç¶šå–ã‚Šè¾¼ã¿ã®ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’èµ·å‹•ã™ã‚‹
                self.threads[i] = Thread(target=self.update, args=([i, hGrabber[i], s, ic, ctypes, tis]), daemon=False)
                print(f"{st} Success ({self.frames[i]} frames {self.w}x{self.h} at {self.fps:.2f} FPS)")
                self.threads[i].start()

            else: # ã‚«ãƒ¡ãƒ©ãŒé–‹ã‘ãªã„æ™‚
                print(f'{st}Failed to open Cam {s}')
        self.rect = True  # dummy code. rect inference if all shapes equal


    def update(self, i, hGrabber, stream, ic, ctypes, tis):
        # Read stream `i` frames in daemon thread
        f, read = self.frames[i], 1  # frame number, frame array, inference every 'read' frame
        Width = ctypes.c_long()
        Height = ctypes.c_long()
        BitsPerPixel = ctypes.c_int()
        colorformat = ctypes.c_int()
        while (ic.IC_IsDevValid(hGrabber)) and self.flag:
            # ã‹ãªã‚Šé•·ã„è¨˜è¿°ã«ãªã‚‹ãŒä»¥ä¸‹self.imgs[i] = im ã¾ã§ã§ç”»åƒã‚’OpenCVã«æ¸¡ã›ã‚‹å½¢ã§å–å¾—ã—ã¦ã„ã‚‹
            if ic.IC_SnapImage(hGrabber) == tis.IC_SUCCESS:
                # Query values of image description
                ic.IC_GetImageDescription(hGrabber, Width, Height, BitsPerPixel, colorformat)
                # Calculate the buffer size
                bpp = int(BitsPerPixel.value / 8.0)
                buffer_size = Width.value * Height.value * BitsPerPixel.value
                imagePtr = ic.IC_GetImagePtr(hGrabber)
                imagedata = ctypes.cast(imagePtr, ctypes.POINTER(ctypes.c_ubyte * buffer_size))
                # Create the numpy array
                im = np.ndarray(buffer=imagedata.contents, dtype=np.uint8, shape=(Height.value, Width.value, bpp))
                im = cv2.flip(im, 0)
                self.imgs[i] = im
                #time.sleep(1 / self.fps)  # wait timeã¯TISã‚«ãƒ¡ãƒ©ã§ã¯ä¸è¦
            
            else: # ç”»åƒãŒä¸Šæ‰‹ãå–ã‚Šè¾¼ã‚ãªã‹ã£ãŸã¨ãã®å‡¦ç†ã€‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡ºã—ã¦ãƒ–ãƒ«ãƒ¼ãƒãƒƒã‚¯ã«ã™ã‚‹ã€‚
                print('WARNING: ç”»åƒãŒæ­£å¸¸ã«å–è¾¼ã‚ã¦ã„ã¾ã›ã‚“ã€‚ã€€ç¢ºèªã®ä¸Šã€ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’å†èµ·å‹•ã—ã¦ä¸‹ã•ã„ã€‚')
                self.imgs[i] =  np.full((Height.value, Width.value, 3), (255, 0, 0), dtype=np.uint8)

        # ä½•ã‚‰ã‹ã®ç†ç”±ã§ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã¦ã—ã¾ã£ãŸå ´åˆã‚‚ãƒ–ãƒ«ãƒ¼ãƒãƒƒã‚¯ç”»åƒã¨ã™ã‚‹ã€‚ã“ã“ã«æ¥ã‚‹ã®ã¯Escã§æ„è­˜çš„ã«æ­¢ã‚ãŸæ™‚ã¨ic.IC_IsDevValid(hGrabber)ãŒFalseã®æ™‚ã€‚
        print('ç”»åƒå–è¾¼ã®ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã¾ã—ãŸã€‚ Cam:', i)
        self.imgs[i] =  np.full((Height.value, Width.value, 3), (255, 0, 0), dtype=np.uint8)
        ic.IC_StopLive(hGrabber)
        ic.IC_ReleaseGrabber(hGrabber)        

    def __iter__(self):
        return self

    def __next__(self):
        if cv2.waitKey(1) == ord('q') or self.rbt_flag: # q to quit 
            self.flag = False
            cv2.destroyAllWindows()
            raise StopIteration

        self.now[0] = self.imgs[0][int(self.h/2) - int(self.bubun/2):int(self.h/2) + int(self.bubun/2), int(self.w/2) - int(self.bubun/2):int(self.w/2) + int(self.bubun/2)]
        self.now[1] = self.imgs[1][int(self.h/2) - int(self.bubun/2):int(self.h/2) + int(self.bubun/2), int(self.w/2) - int(self.bubun/2):int(self.w/2) + int(self.bubun/2)]   
        self.now[2] = self.imgs[2][int(self.h/2) - int(self.bubun/2):int(self.h/2) + int(self.bubun/2), int(self.w/2) - int(self.bubun/2):int(self.w/2) + int(self.bubun/2)]
        self.now[3] = self.imgs[3][int(self.h/2) - int(self.bubun/2):int(self.h/2) + int(self.bubun/2), int(self.w/2) - int(self.bubun/2):int(self.w/2) + int(self.bubun/2)] 
        if (self.now[0] == self.maeno[0]).all() or (self.now[1] == self.maeno[1]).all() or (self.now[2] == self.maeno[2]).all() or (self.now[3] == self.maeno[3]).all():
            self.cnt +=1
            if self.cnt >= self.fps * 1 : # ç”»åƒãŒæ›´æ–°ã•ã‚Œãªã„ã¨ã„ã†åˆ¤æ–­ãŒæ•°ç§’ç¶šã„ãŸã‚‰â€¦
                self.flag = False
                if (self.now[0] == self.maeno[0]).all():
                    self.bad_cam = "å·¦ä¸Š"
                elif (self.now[1] == self.maeno[1]).all():
                    self.bad_cam = "å³ä¸Š"                            
                elif (self.now[2] == self.maeno[2]).all():
                    self.bad_cam = "å³ä¸‹"
                elif (self.now[3] == self.maeno[3]).all():
                    self.bad_cam = "å·¦ä¸‹"
                self.rbt_flag = True # çµ‚äº†å¾Œã€è‡ªåˆ†ã‚’å†èµ·å‹•ã™ã‚‹ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹
        else:
            self.cnt = 0 # æ¯”è¼ƒçµæœãŒç•°ãªã‚Œã°ã‚«ã‚¦ãƒ³ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ

        # ã“ã“ã§4ã¤ã®ç”»åƒã‚’åˆæˆã™ã‚‹
        self.concimg = cv2.hconcat([self.imgs[0], self.imgs[1]])
        conc2 = cv2.hconcat([self.imgs[3], self.imgs[2]])
        self.concimg = cv2.vconcat([self.concimg, conc2])
        self.concimg = cv2.resize(self.concimg, (800, 600), interpolation = cv2.INTER_AREA)
        self.obi = np.full((20, 800, 3), (255, 255, 255), dtype=np.uint8)
        self.concimg = cv2.vconcat([self.concimg, self.obi])
        #self.concimg = np.expand_dims(self.concimg, axis=0) # CHW > BCHW 

        self.maeno[0] = self.now[0] # æ¯”è¼ƒç”¨ç”»åƒã®å…¥ã‚Œæ›¿ãˆ
        self.maeno[1] = self.now[1] # æ¯”è¼ƒç”¨ç”»åƒã®å…¥ã‚Œæ›¿ãˆ
        self.maeno[2] = self.now[2] # æ¯”è¼ƒç”¨ç”»åƒã®å…¥ã‚Œæ›¿ãˆ
        self.maeno[3] = self.now[3] # æ¯”è¼ƒç”¨ç”»åƒã®å…¥ã‚Œæ›¿ãˆ

        img0 = self.concimg.copy()
        # Letterbox
        img_lb = letterbox(img0)[0] # letterboxé–¢æ•°ã‹ã‚‰è¿”ã£ã¦ããŸç”»åƒéƒ¨åˆ†ã®ã¿

        return self.sources, img_lb, img0, self.rbt_flag, self.bad_cam

class LoadV4TISCams:
    # Vertical
    def __init__(self, sources='V4TISCams.txt', img_size=640, stride=32, auto=True):
        self.mode = 'stream'
        self.img_size = img_size
        self.stride = stride
        self.flag = True
        self.rbt_flag = False # ãƒ‡ãƒã‚¤ã‚¹ãƒ­ã‚¹ãƒˆãªã©ã§è‡ªå‹•çš„ã«è‡ªåˆ†ã‚’æ­¢ã‚ã‚‹ï¼ˆå†èµ·å‹•è¦å¦ã®ç›®å°ï¼‰ãƒ•ãƒ©ã‚°
        self.bubun = 40 # å‰ã¨æ–°ã—ã„ç”»åƒã®æ¯”è¼ƒã«ä½¿ã†å››è§’å½¢éƒ¨åˆ†ã®ä¸€è¾ºã®ãƒ”ã‚¯ã‚»ãƒ«æ•° â˜…å¿…ãšå¶æ•°ã«ã™ã‚‹ã“ã¨ï¼ï¼ï¼
        self.bad_cam = "" # ãƒ‡ãƒã‚¤ã‚¹ãƒ­ã‚¹ãƒˆã—ãŸã‚«ãƒ¡ãƒ©ã®ä½ç½®æƒ…å ±ã‚’æ¸¡ã™å¤‰æ•°

        if os.path.isfile(sources):
            with open(sources) as f:
                sources = [x.strip() for x in f.read().strip().splitlines() if len(x.strip()) and x[0] != '#']
        else:
            sources = [sources]

        print(sources)
        n = len(sources)
        try:
            # TISã‚«ãƒ¡ãƒ©ã®ãŸã‚ã«importã™ã‚‹
            import ctypes
            import tisgrabber as tis
        except:
            print('tisgrabber is not installed. Please check !')
            sys.exit(0)
        self.imgs, self.fps, self.frames, self.threads = [None] * 4, [0] * n, [0] * n, [None] * n
        self.sources = [clean_str(x) for x in sources]  # clean source names for later
        self.auto = auto

        self.cnt = 0 # maenoã¨nowã®åŒä¸€ç”»åƒæ¤œå‡ºã®å›æ•°ã‚«ã‚¦ãƒ³ã‚¿
        self.maeno = [None] * 4 # æ¯”è¼ƒç”¨ç”»åƒã‚’ä¿å­˜ã™ã‚‹å¤‰æ•°
        self.now = [None] * 4
        for i in range(4): # åˆã‚ã«ç”»åƒæ¯”è¼ƒç”¨ã®å‰ã®ç”»åƒã«å½“ãŸã‚‹ã‚‚ã®ã‚’ç”¨æ„ã—ã¦ãŠã
            self.maeno[i] = np.full((self.bubun, self.bubun, 3), (0, 255, 0), dtype=np.uint8)  

        self.fps = 70
        self.w = 720 #640
        self.h = 180 #160 # temporary definition
        vformat = "RGB24 ({0}x{1})".format(self.w, self.h) # ã‚«ãƒ¡ãƒ©ã®ãƒ“ãƒ‡ã‚ªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’æŒ‡å®šã™ã‚‹å®šæ•°ã€€WDRæ©Ÿèƒ½ã‚’ä½¿ã†ã®ã§RGB64ã¨ã—ãŸã€‚
        
        ic = ctypes.cdll.LoadLibrary("./tisgrabber_x64.dll") # TISãŠã¾ã˜ãªã„1
        tis.declareFunctions(ic) # TISãŠã¾ã˜ãªã„2
        ic.IC_InitLibrary(0) # TISãŠã¾ã˜ãªã„3
        hGrabber = [None] * 4 # ã‚«ãƒ¡ãƒ©ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆã‚’å®šç¾©ã—ã¦ãŠã
        # ã‚«ãƒ¡ãƒ©ã®ç«‹ä¸Šã‚Šé †ã«ã‚ˆã‚‹ã‚¨ãƒ©ãƒ¼ã‚’å›é¿ã™ã‚‹ãŸã‚ã«äºˆã‚èµ¤è‰²ã®ç”»é¢ã‚’ã‚«ãƒ¡ãƒ©ã®æ•°ã ã‘ç”¨æ„ã—ã¦ãŠã
        for i in range(4):  # index, source
            self.imgs[i] = np.full((self.h, self.w, 3), (0, 0, 255), dtype=np.uint8)

        for i, s in enumerate(sources):  # index, source
            self.frames[i] = float('inf')  # infinite stream fallback
            # Start thread to read frames from video stream
            st = f'{i + 1}/{n}: {s}... '
            s = str(s)
            hGrabber[i] = ic.IC_CreateGrabber()
            ic.IC_OpenDevByUniqueName(hGrabber[i], tis.T(s)) # ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼ã®æŒ‡å®šã‚‚å¯èƒ½
            ic.IC_SetVideoFormat(hGrabber[i], tis.T(vformat))
            if (ic.IC_IsDevValid(hGrabber[i])): # ã‚«ãƒ¡ãƒ©ãŒé–‹ã‘ãŸã‚‰
                #ic.IC_printItemandElementNames(hGrabber[i])
                # ã‚«ãƒ¡ãƒ©ã®éœ²å…‰æ™‚é–“ã€FPSã€ãƒ›ãƒ¯ã‚¤ãƒˆãƒãƒ©ãƒ³ã‚¹ã€ã‚²ã‚¤ãƒ³ãªã©ã‚’è¨­å®šã™ã‚‹ 

                # WDRï¼ˆãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãƒ¬ãƒ³ã‚¸ã‚’åºƒã’ã¦æ˜ã‚‹ãã™ã‚‹ï¼‰ã‚’ã‚»ãƒƒãƒˆã—ã¦ã¿ã‚‹ã€€â€»æ’šç·šæ©Ÿã®ç”»è³ªæ”¹å–„ã®ãŸã‚
                ic.IC_SetPropertySwitch(hGrabber[i], tis.T("Tone Mapping"), tis.T("Enable"), 1)
                ic.IC_SetPropertySwitch(hGrabber[i], tis.T("Tone Mapping"), tis.T("Auto"), 0)
                ic.IC_SetPropertyAbsoluteValue(hGrabber[i], tis.T("Tone Mapping"), tis.T("Intensity"), ctypes.c_float(0.5))
                ic.IC_SetPropertyAbsoluteValue(hGrabber[i], tis.T("Tone Mapping"), tis.T("Global Brightness Factor"), ctypes.c_float(0.0))
                #ic.IC_SetPropertySwitch(hGrabber[i], tis.T("Tone Mapping"), tis.T("Enable"), 0)

                #Gamma: 0.1-5.0 default 1.0
                ic.IC_SetPropertyAbsoluteValue(hGrabber[i], tis.T("Gamma"), tis.T("Value"), ctypes.c_float(0.7))

                # fps: - 549 ã¨ Exposure ï¼š0.000001 - 30.0              
                ic.IC_SetFrameRate(hGrabber[i], ctypes.c_float(self.fps))
                ic.IC_SetPropertySwitch(hGrabber[i], tis.T("Exposure"), tis.T("Auto"), 0)
                ic.IC_SetPropertyAbsoluteValue(hGrabber[i], tis.T("Exposure"), tis.T("Value"), ctypes.c_float(0.004))
                #Brightness : 0 - 4095 Default 240
                ic.IC_SetPropertyValue(hGrabber[i], tis.T("Brightness"), tis.T("Value"),ctypes.c_int(240))
                #Gain :0.0 - 48.0 Default 1.0
                ic.IC_SetPropertySwitch(hGrabber[i], tis.T("Gain"), tis.T("Auto"), 0)
                ic.IC_SetPropertyAbsoluteValue(hGrabber[i], tis.T("Gain"), tis.T("Value"), ctypes.c_float(25.0))
                #WhiteBalance ï¼š å„è‰² 0.0 - 3.984375 â€»IC Captureãªã©ã§å®Ÿå†™ã‚’è¦‹ã¦èª¿æ•´
                ic.IC_SetPropertySwitch(hGrabber[i], tis.T("WhiteBalance"), tis.T("Auto"), 0)
                ic.IC_SetPropertyAbsoluteValue(hGrabber[i], tis.T("WhiteBalance"), tis.T("White Balance Red"), ctypes.c_float(1.66))
                ic.IC_SetPropertyAbsoluteValue(hGrabber[i], tis.T("WhiteBalance"), tis.T("White Balance Green"), ctypes.c_float(1.00))              
                ic.IC_SetPropertyAbsoluteValue(hGrabber[i], tis.T("WhiteBalance"), tis.T("White Balance Blue"), ctypes.c_float(2.48))
                # ã“ã“ã¾ã§ã§ã‚«ãƒ¡ãƒ©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šã¯çµ‚äº†
                
                # Start the live video stream, but show no own live video window. We will use OpenCV for this.
                ic.IC_StartLive(hGrabber[i], 0) # å¼•æ•°ã‚’ã€Œï¼‘ã€ã«ã™ã‚‹ã¨ãƒ©ã‚¤ãƒ–ç”»åƒãŒé–‹ãã€‚OpenCVã§ã®æç”»ã‚’ã™ã‚‹ã®ã§ã€Œï¼ã€ã¨ã™ã‚‹ã€‚
                #print('â˜…â˜…ic.IC_SnapImage(hGrabber[',i, ']: ', ic.IC_SnapImage(hGrabber[i])) #debugprint

                # é€£ç¶šå–ã‚Šè¾¼ã¿ã®ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’èµ·å‹•ã™ã‚‹
                self.threads[i] = Thread(target=self.update, args=([i, hGrabber[i], s, ic, ctypes, tis]), daemon=False)
                print(f"{st} Success ({self.frames[i]} frames {self.w}x{self.h} at {self.fps:.2f} FPS)")
                self.threads[i].start()

            else: # ã‚«ãƒ¡ãƒ©ãŒé–‹ã‘ãªã„æ™‚
                print(f'{st}Failed to open Cam {s}')
        self.rect = True  # dummy code. rect inference if all shapes equal

    def update(self, i, hGrabber, stream, ic, ctypes, tis):
        # Read stream `i` frames in daemon thread
        f, read = self.frames[i], 1  # frame number, frame array, inference every 'read' frame
        Width = ctypes.c_long()
        Height = ctypes.c_long()
        BitsPerPixel = ctypes.c_int()
        colorformat = ctypes.c_int()
        while (ic.IC_IsDevValid(hGrabber)) and self.flag:
            # ã‹ãªã‚Šé•·ã„è¨˜è¿°ã«ãªã‚‹ãŒä»¥ä¸‹self.imgs[i] = im ã¾ã§ã§ç”»åƒã‚’OpenCVã«æ¸¡ã›ã‚‹å½¢ã§å–å¾—ã—ã¦ã„ã‚‹
            if ic.IC_SnapImage(hGrabber) == tis.IC_SUCCESS:
                # Query values of image description
                ic.IC_GetImageDescription(hGrabber, Width, Height, BitsPerPixel, colorformat)
                # Calculate the buffer size
                bpp = int(BitsPerPixel.value / 8.0)
                buffer_size = Width.value * Height.value * BitsPerPixel.value
                imagePtr = ic.IC_GetImagePtr(hGrabber)
                imagedata = ctypes.cast(imagePtr, ctypes.POINTER(ctypes.c_ubyte * buffer_size))
                # Create the numpy array
                im = np.ndarray(buffer=imagedata.contents, dtype=np.uint8, shape=(Height.value, Width.value, bpp))
                im = cv2.flip(im, 0)
                self.imgs[i] = im
                #time.sleep(1 / self.fps)  # wait timeã¯TISã‚«ãƒ¡ãƒ©ã§ã¯ä¸è¦
            
            else: # ç”»åƒãŒä¸Šæ‰‹ãå–ã‚Šè¾¼ã‚ãªã‹ã£ãŸã¨ãã®å‡¦ç†ã€‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡ºã—ã¦ãƒ–ãƒ«ãƒ¼ãƒãƒƒã‚¯ã«ã™ã‚‹ã€‚
                print('WARNING: ç”»åƒãŒæ­£å¸¸ã«å–è¾¼ã‚ã¦ã„ã¾ã›ã‚“ã€‚ã€€ç¢ºèªã®ä¸Šã€ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’å†èµ·å‹•ã—ã¦ä¸‹ã•ã„ã€‚')
                self.imgs[i] =  np.full((Height.value, Width.value, 3), (255, 0, 0), dtype=np.uint8)
                #cap.open(stream)  # re-open stream if signal was lost         

        # ä½•ã‚‰ã‹ã®ç†ç”±ã§ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã¦ã—ã¾ã£ãŸå ´åˆã‚‚ãƒ–ãƒ«ãƒ¼ãƒãƒƒã‚¯ç”»åƒã¨ã™ã‚‹ã€‚ã“ã“ã«æ¥ã‚‹ã®ã¯Escã§æ„è­˜çš„ã«æ­¢ã‚ãŸæ™‚ã¨ic.IC_IsDevValid(hGrabber)ãŒFalseã®æ™‚ã€‚
        print('ç”»åƒå–è¾¼ã®ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã¾ã—ãŸã€‚ Cam:', i)
        self.imgs[i] =  np.full((Height.value, Width.value, 3), (255, 0, 0), dtype=np.uint8)
        ic.IC_StopLive(hGrabber)
        ic.IC_SetPropertySwitch(hGrabber, tis.T("Tone Mapping"), tis.T("Enable"), 0)
        ic.IC_ReleaseGrabber(hGrabber)        

    def __iter__(self):
        return self

    def __next__(self):
        #if not all(x.isAlive() for x in self.threads) or cv2.waitKey(1) == 27: #ord('q'):  # q to quit
        if cv2.waitKey(1) == ord('q') or self.rbt_flag: # q to quit 
            self.flag = False
            cv2.destroyAllWindows()
            raise StopIteration

        # æ¯”è¼ƒç”¨ç”»åƒã®åˆ‡ã‚Šå‡ºã—
        self.now[0] = self.imgs[0][int(self.h/2) - int(self.bubun/2):int(self.h/2) + int(self.bubun/2), int(self.w/2) - int(self.bubun/2):int(self.w/2) + int(self.bubun/2)]
        self.now[1] = self.imgs[1][int(self.h/2) - int(self.bubun/2):int(self.h/2) + int(self.bubun/2), int(self.w/2) - int(self.bubun/2):int(self.w/2) + int(self.bubun/2)]   
        self.now[2] = self.imgs[2][int(self.h/2) - int(self.bubun/2):int(self.h/2) + int(self.bubun/2), int(self.w/2) - int(self.bubun/2):int(self.w/2) + int(self.bubun/2)]
        self.now[3] = self.imgs[3][int(self.h/2) - int(self.bubun/2):int(self.h/2) + int(self.bubun/2), int(self.w/2) - int(self.bubun/2):int(self.w/2) + int(self.bubun/2)] 
        if (self.now[0] == self.maeno[0]).all() or (self.now[1] == self.maeno[1]).all() or (self.now[2] == self.maeno[2]).all() or (self.now[3] == self.maeno[3]).all():
            self.cnt +=1
            if self.cnt >= self.fps * 1 : # ç”»åƒãŒæ›´æ–°ã•ã‚Œãªã„ã¨ã„ã†åˆ¤æ–­ãŒæ•°ç§’ç¶šã„ãŸã‚‰â€¦
                self.flag = False
                if (self.now[0] == self.maeno[0]).all():
                    self.bad_cam = "ä¸€ç•ªä¸Š"
                elif (self.now[1] == self.maeno[1]).all():
                    self.bad_cam = "äºŒç•ªç›®"                            
                elif (self.now[2] == self.maeno[2]).all():
                    self.bad_cam = "ä¸‰ç•ªç›®"
                elif (self.now[3] == self.maeno[3]).all():
                    self.bad_cam = "ä¸€ç•ªä¸‹"
                self.rbt_flag = True # çµ‚äº†å¾Œã€è‡ªåˆ†ã‚’å†èµ·å‹•ã™ã‚‹ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹
        else:
            self.cnt = 0 # æ¯”è¼ƒçµæœãŒç•°ãªã‚Œã°ã‚«ã‚¦ãƒ³ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ
            
        # ã“ã“ã§4ã¤ã®ç”»åƒã‚’åˆæˆã™ã‚‹
        self.concimg = cv2.vconcat([self.imgs[0], self.imgs[1]])
        conc2 = cv2.vconcat([self.imgs[2], self.imgs[3]])
        self.concimg = cv2.vconcat([self.concimg, conc2])
        self.concimg = cv2.resize(self.concimg, (self.w, 4*self.h), interpolation = cv2.INTER_AREA)
        self.obi = np.full((20, self.w, 3), (255, 255, 255), dtype=np.uint8)
        self.concimg = cv2.vconcat([self.obi, self.concimg, self.obi])
        #self.concimg = np.expand_dims(self.concimg, axis=0) # CHW > BCHW 

        self.maeno[0] = self.now[0] # æ¯”è¼ƒç”¨ç”»åƒã®å…¥ã‚Œæ›¿ãˆ
        self.maeno[1] = self.now[1] # æ¯”è¼ƒç”¨ç”»åƒã®å…¥ã‚Œæ›¿ãˆ
        self.maeno[2] = self.now[2] # æ¯”è¼ƒç”¨ç”»åƒã®å…¥ã‚Œæ›¿ãˆ
        self.maeno[3] = self.now[3] # æ¯”è¼ƒç”¨ç”»åƒã®å…¥ã‚Œæ›¿ãˆ

        img0 = self.concimg.copy()
        # Letterbox
        img_lb = letterbox(img0)[0] # letterboxé–¢æ•°ã‹ã‚‰è¿”ã£ã¦ããŸç”»åƒéƒ¨åˆ†ã®ã¿

        return self.sources, img_lb, img0, self.rbt_flag, self.bad_cam

class LoadT4Streams:
    # for USB camera  Tile
    def __init__(self, sources='streams.txt', img_size=640, stride=32, auto=True):
        global flag
        self.mode = 'stream'
        self.img_size = img_size
        self.stride = stride
        self.flag = True # è¤‡æ•°é–‹ã„ãŸã‚«ãƒ¡ãƒ©ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‰ã˜ã‚‹ãŸã‚ã®ãƒ•ãƒ©ã‚°
        self.w = 640
        self.h = 480

        if os.path.isfile(sources):
            with open(sources) as f:
                sources = [x.strip() for x in f.read().strip().splitlines() if len(x.strip()) and x[0] != '#']
        else:
            sources = [sources]

        print(sources)
        n = len(sources)
        self.imgs, self.fps, self.frames, self.threads = [None] * 4, [0] * n, [0] * n, [None] * n
        self.sources = [clean_str(x) for x in sources]  # clean source names for later
        self.auto = auto
        # ã‚«ãƒ¡ãƒ©ã®ç«‹ã¡ä¸ŠãŒã‚Šæ–¹æ¬¡ç¬¬ã§ã‚¨ãƒ©ãƒ¼ã‚’èµ·ã“ã™ã“ã¨ã‚ã‚‹ã®ã§ã€äºˆã‚èµ¤è‰²ã®ç”»é¢ã‚’ã‚«ãƒ¡ãƒ©ã®æ•°ã ã‘ç”¨æ„ã—ã¦ãŠã
        for i, s in enumerate(sources):  # index, source
            self.imgs[i] = np.full((self.h, self.w, 3), (0, 0, 255), dtype=np.uint8)

        for i, s in enumerate(sources):  # index, source
            # Start thread to read frames from video stream
            st = f'{i + 1}/{n}: {s}... '
            s = eval(s) if s.isnumeric() else s  # i.e. s = '0' local webcam
            cap = cv2.VideoCapture(s + cv2.CAP_DSHOW)
            #assert cap.isOpened(), f'{st}Failed to open {s}'
            w = self.w #int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            h = self.h #int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            self.fps[i] = max(cap.get(cv2.CAP_PROP_FPS) % 100, 0) or 30.0  # 30 FPS fallback
            self.frames[i] = max(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)), 0) or float('inf')  # infinite stream fallback

            if cap.isOpened():
                _, self.imgs[i] = cap.read()  # guarantee first frame
                self.threads[i] = Thread(target=self.update, args=([i, cap, s]), daemon=False)
                # threadsã¯ã€daemon=Trueã§è¤‡æ•°èµ·å‹•ã™ã‚‹ã¨çµ‚äº†æ™‚ã«ã‚«ãƒ¡ãƒ©ã‚’é–‹æ”¾ã—ãªããªã‚‹ã€‚ãã®ãŸã‚daemon=Falseï¼ˆãƒ‡ãƒ•ã‚©ï¼‰ã¨ã—ãŸã€‚
                print(f"{st} Success ({self.frames[i]} frames {w}x{h} at {self.fps[i]:.2f} FPS)")
                self.threads[i].start()
                #print('** ', self.threads) # debug print
            else:
                print(f'{st}Failed to open Cam {s}')
                self.imgs[i] = np.full((self.h, self.w, 3), (128, 128, 128), dtype=np.uint8)

        print('')  # newline
		
        self.rect = True #np.unique(s, axis=0).shape[0] == 1  # rect inference if all shapes equal

    def update(self, i, cap, stream):
        # Read stream `i` frames in daemon thread
        n, f, read = 0, self.frames[i], 1  # frame number, frame array, inference every 'read' frame
        while cap.isOpened() and n < f and self.flag: # flagã‚‚ãƒ«ãƒ¼ãƒ—ã®æ¡ä»¶ã«åŠ ãˆã¦ã„ã‚‹
            start_t = time.perf_counter()
            n += 1
            #_, self.imgs[i] = cap.read()
            cap.grab()
            if n % read == 0:
                success, im = cap.retrieve()
                if success:
                    self.imgs[i] = im
                else:
                    print('WARNING: Video stream unresponsive, please check your IP camera connection.')
                    self.imgs[i] = np.zeros_like(self.imgs[i])
                    cap.open(stream)  # re-open stream if signal was lost
            end_t = time.perf_counter()
            print(str(i) + 'ã€€elapse time = {:.3f} Seconds'.format((end_t - start_t))) 
            time.sleep(1 / self.fps[i])  # wait time
        cap.release() # ç„¡é™ãƒ«ãƒ¼ãƒ—ã‹ã‚‰æŠœã‘ãŸã‚‰ã‚«ãƒ¡ãƒ©ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’é–‹æ”¾ã™ã‚‹ã®ã‚’å¿˜ã‚Œãªã„ã“ã¨ï¼

    def __iter__(self):
        self.count = -1
        return self

    def __next__(self):
        self.count += 1
        #if not all(x.isAlive() for x in self.threads) or cv2.waitKey(1) == 27: #ord('q'):  # q to quit
        if cv2.waitKey(1) == ord('q'):  # q to quit 
            self.flag = False # ç”»åƒå–è¾¼ã®ç„¡é™ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹ãŸã‚ãƒ•ãƒ©ã‚°ã‚’æ›¸ãæ›ãˆã‚‹
            cv2.destroyAllWindows()          
            raise StopIteration

        #h, w, _ = self.imgs[0].shape # ç”»åƒã®ã‚µã‚¤ã‚ºã‚’å–è¾¼ã‚“ã§ãŠã
        # ã“ã“ã§4ã¤ã®ç”»åƒã‚’åˆæˆã™ã‚‹
        if len(self.sources) == 1:
            self.imgs[1] = np.full((self.h, self.w, 3), (128, 128, 128), dtype=np.uint8)
        self.concimg = cv2.hconcat([self.imgs[0], self.imgs[1]])
        if len(self.sources) > 2:
            if len(self.sources) == 3:
                self.imgs[3] = np.full((self.h, self.w, 3), (128, 128, 128), dtype=np.uint8)
            conc2 = cv2.hconcat([self.imgs[2], self.imgs[3]])
            self.concimg = cv2.vconcat([self.concimg, conc2])
            self.concimg = cv2.resize(self.concimg, (800, 600), interpolation = cv2.INTER_AREA)
        else:
            self.concimg = cv2.resize(self.concimg, (800, 300), interpolation = cv2.INTER_AREA)
        self.obi = np.full((20, 800, 3), (255, 255, 255), dtype=np.uint8)
        self.concimg = cv2.vconcat([self.concimg, self.obi])
        #self.concimg = np.expand_dims(self.concimg, axis=0) # CHW > BCHW 

        img0 = self.concimg.copy()
        # Letterbox
        img_lb = letterbox(img0)[0] # letterboxé–¢æ•°ã‹ã‚‰è¿”ã£ã¦ããŸç”»åƒéƒ¨åˆ†ã®ã¿

        return self.sources, img_lb, img0, self.rbt_flag, self.bad_cam

    def __len__(self):
        return len(self.sources)  # 1E12 frames = 32 streams at 30 FPS for 30 years

class LoadV4Streams:
    # for USB camera  Vertical
    def __init__(self, sources='Vstreams.txt', img_size=640, stride=32, auto=True):
        global flag
        self.mode = 'stream'
        self.img_size = img_size
        self.stride = stride
        self.flag = True # è¤‡æ•°é–‹ã„ãŸã‚«ãƒ¡ãƒ©ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‰ã˜ã‚‹ãŸã‚ã®ãƒ•ãƒ©ã‚°

        if os.path.isfile(sources):
            with open(sources) as f:
                sources = [x.strip() for x in f.read().strip().splitlines() if len(x.strip()) and x[0] != '#']
        else:
            sources = [sources]

        print(sources)
        n = len(sources)
        self.imgs, self.fps, self.frames, self.threads = [None] * 4, [0] * n, [0] * n, [None] * n
        self.sources = [clean_str(x) for x in sources]  # clean source names for later
        self.auto = auto
        self.w = 640 #int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        self.h = 160 #int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        full_h = 480 # ã‚¯ãƒ­ãƒƒãƒ—ã—ãªã„å ´åˆã®ç¸¦ç”»ç´ æ•°
        self.start_h = int((full_h - self.h) / 2)
        # äºˆã‚èµ¤è‰²ã®ç”»é¢ã‚’ã‚«ãƒ¡ãƒ©ã®æ•°ã ã‘ç”¨æ„ã—ã¦ãŠã
        for i, s in enumerate(sources):  # index, source
            self.imgs[i] = np.full((self.h, self.w, 3), (0, 0, 255), dtype=np.uint8)

        for i, s in enumerate(sources):  # index, source
            # Start thread to read frames from video stream
            st = f'{i + 1}/{n}: {s}... '
            s = eval(s) if s.isnumeric() else s  # i.e. s = '0' local webcam
            cap = cv2.VideoCapture(s + cv2.CAP_DSHOW)
            #assert cap.isOpened(), f'{st}Failed to open {s}'

            self.fps[i] = max(cap.get(cv2.CAP_PROP_FPS) % 100, 0) or 30.0  # 30 FPS fallback
            self.frames[i] = max(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)), 0) or float('inf')  # infinite stream fallback

            if cap.isOpened():
                _, im = cap.read()  # guarantee first frame
                self.imgs[i] = im[self.start_h:(self.start_h + self.h), 0:self.w] # crop
                self.threads[i] = Thread(target=self.update, args=([i, cap, s]), daemon=False)
                # threadsã¯ã€daemon=Trueã§è¤‡æ•°èµ·å‹•ã™ã‚‹ã¨çµ‚äº†æ™‚ã«ã‚«ãƒ¡ãƒ©ã‚’é–‹æ”¾ã—ãªããªã‚‹ã€‚ãã®ãŸã‚daemon=Falseï¼ˆãƒ‡ãƒ•ã‚©ï¼‰ã¨ã—ãŸã€‚
                print(f"{st} Success ({self.frames[i]} frames {self.w}x{self.h} at {self.fps[i]:.2f} FPS)")
                self.threads[i].start()
                #print('** ', self.threads) # debug print
            else:
                print(f'{st}Failed to open Cam {s}')
                self.imgs[i] = np.full((self.h, self.w, 3), (128, 128, 128), dtype=np.uint8)

        print('')  # newline
        
        self.rect = True #np.unique(s, axis=0).shape[0] == 1  # rect inference if all shapes equal

    def update(self, i, cap, stream):
        # Read stream `i` frames in daemon thread
        n, f, read = 0, self.frames[i], 1  # frame number, frame array, inference every 'read' frame
        while cap.isOpened() and n < f and self.flag: # flagã‚‚ãƒ«ãƒ¼ãƒ—ã®æ¡ä»¶ã«åŠ ãˆã¦ã„ã‚‹
            n += 1
            #_, self.imgs[i] = cap.read()
            cap.grab()
            if n % read == 0:
                success, im = cap.retrieve()
                if success:

                    self.imgs[i] = im[self.start_h:(self.start_h + self.h), 0:self.w] # å–ã‚Šè¾¼ã‚“ã ç”»åƒã®é«˜ã•æ–¹å‘ã§ä¸­å¿ƒéƒ¨åˆ†ã ã‘ã‚’ä½¿ã†
                else:
                    print('WARNING: Video stream unresponsive, please check your IP camera connection.')
                    self.imgs[i] = np.zeros_like(self.imgs[i])
                    cap.open(stream)  # re-open stream if signal was lost
            time.sleep(1 / self.fps[i])  # wait time
        cap.release() # ç„¡é™ãƒ«ãƒ¼ãƒ—ã‹ã‚‰æŠœã‘ãŸã‚‰ã‚«ãƒ¡ãƒ©ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’é–‹æ”¾ã™ã‚‹ã®ã‚’å¿˜ã‚Œãªã„ã“ã¨ï¼

    def __iter__(self):
        self.count = -1
        return self

    def __next__(self):
        self.count += 1
        #if not all(x.isAlive() for x in self.threads) or cv2.waitKey(1) == 27: #ord('q'):  # q to quit
        if cv2.waitKey(1) == 27: #ord('q'):  # q to quit 
            self.flag = False # ç”»åƒå–è¾¼ã®ç„¡é™ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹ãŸã‚ãƒ•ãƒ©ã‚°ã‚’æ›¸ãæ›ãˆã‚‹
            cv2.destroyAllWindows()          
            raise StopIteration

        h, w, _ = self.imgs[0].shape # ç”»åƒã®ã‚µã‚¤ã‚ºã‚’å–è¾¼ã‚“ã§ãŠã
        # ã“ã“ã§4ã¤ã®ç”»åƒã‚’åˆæˆã™ã‚‹
        if len(self.sources) == 1:
            self.imgs[1] = np.full((self.h, self.w, 3), (128, 128, 128), dtype=np.uint8)
        self.concimg = cv2.vconcat([self.imgs[0], self.imgs[1]])
        if len(self.sources) > 2:
            if len(self.sources) == 3:
                self.imgs[3] = np.full((self.h, self.w, 3), (128, 128, 128), dtype=np.uint8)
            conc2 = cv2.vconcat([self.imgs[2], self.imgs[3]])
            self.concimg = cv2.vconcat([self.concimg, conc2])
            self.concimg = cv2.resize(self.concimg, (self.w, 4*self.h), interpolation = cv2.INTER_AREA)
        else:
            self.concimg = cv2.resize(self.concimg, (self.w, 2*self.h), interpolation = cv2.INTER_AREA)
        self.obi = np.full((20, self.w, 3), (255, 255, 255), dtype=np.uint8)
        self.concimg = cv2.vconcat([self.concimg, self.obi])
        self.concimg = np.expand_dims(self.concimg, axis=0) # CHW > BCHW 

        img0 = self.concimg.copy()
        # Letterbox
        img_lb = letterbox(img0)[0] # letterboxé–¢æ•°ã‹ã‚‰è¿”ã£ã¦ããŸç”»åƒéƒ¨åˆ†ã®ã¿

        return self.sources, img_lb, img0, self.rbt_flag, self.bad_cam

    def __len__(self):
        return len(self.sources)  # 1E12 frames = 32 streams at 30 FPS for 30 years

