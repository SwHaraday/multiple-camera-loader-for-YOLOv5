# THIS ğŸ“· by SWCC Corporation, GPL-3.0 license
"""
usage :
    dataset = LoadV4TISCams(source, img_size=640, stride=32, auto=True)
"""

import os, sys
import codecs
import time
from threading import Thread
import re
import cv2
import numpy as np
import torch
import warnings
warnings.filterwarnings("ignore") # Warning will make operation confuse!!!

def clean_str(s):
    # Cleans a string by replacing special characters with underscore _
    return re.sub(pattern="[|@#!Â¡Â·$â‚¬%&()=?Â¿^*;:,Â¨Â´><+]", repl="_", string=s)

def letterbox(
    im,
    new_shape=(640, 640),
    color=(114, 114, 114),
    scaleup=True,
    stride=32,
):
    shape = im.shape[:2]  # current shape [height, width]

    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])
    if not scaleup:  # only scale down, do not scale up (for better val mAP)
        r = min(r, 1.0)

    ratio = r, r  # width, height ratios
    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))
    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding

    dw /= 2
    dh /= 2

    if shape[::-1] != new_unpad:  # resize
        im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)
    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))
    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))
    im = cv2.copyMakeBorder(
        im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color
    )
    return im, ratio, (dw, dh)

def get_camera_params(source):
    # å¼•æ•°ã§æ¸¡ã•ã‚ŒãŸã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å…ƒã«è¨­å®šå€¤ã‚’è¾æ›¸ã¨ã—ã¦è¿”ã™é–¢æ•°
    source = str(source) # å¼•æ•°ãŒæ•´æ•°ã§ã‚‚è€ãˆã‚‹ã‚ˆã†ã«â€¦
    fn = source + '.txt'
    with codecs.open(fn, 'r', 'utf-8') as f: 
        # è¡Œé ­æ–‡å­—ãŒã€Œï¼ƒã€ã§ç„¡ã„ã‚‚ã®ã‚’å–ã‚Šè¾¼ã‚€ã€Œã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ æ•°å€¤ã€ã®ãƒªã‚¹ãƒˆã«ãªã‚‹
        params=[x.strip() for x in f.read().strip().splitlines() if len(x.strip()) and x[0] != '#']
    # dictå‹å¤‰æ•°ã‚’ç”¨æ„
    p_dict={}
    for x in params: # ãƒªã‚¹ãƒˆã®å„è¦ç´ ã‚’ã‚¹ãƒšãƒ¼ã‚¹ã§åˆ†ã‘ã¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨æ•°å€¤ã¨ã—ã¦æ›¸ãè¾¼ã‚€
        # split()ã¯åŠè§’/å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ãŒæ··åœ¨ã—ã‚ˆã†ãŒã€ã„ãã¤ä¸¦ã‚“ã§ã„ã‚ˆã†ãŒã€é–¢ä¿‚ãªãã‚¹ãƒšãƒ¼ã‚¹ã§åˆ†ã‘ã¦ãã‚Œã‚‹
        p_dict[x.split()[0]] = x.split()[1] 
    return p_dict

def set_camera_params(p_dict, i, hGrabber, ic, ctypes, tis):
    # å—ã‘å–ã£ãŸè¨­å®šå€¤ï¼ˆè¾æ›¸å‹ï¼šp_dictï¼‰ã«å¾“ã£ã¦æŒ‡å®šã•ã‚ŒãŸã‚«ãƒ¡ãƒ©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®šã™ã‚‹ã€‚
    # ã‚«ãƒ¡ãƒ©ã®éœ²å…‰æ™‚é–“ã€FPSã€ãƒ›ãƒ¯ã‚¤ãƒˆãƒãƒ©ãƒ³ã‚¹ã€ã‚²ã‚¤ãƒ³ãªã©ã‚’è¨­å®šã™ã‚‹
    if 'Intensity' in p_dict and 'GlobalBrightnessFactor' in p_dict:
        # WDRï¼ˆãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãƒ¬ãƒ³ã‚¸ã‚’åºƒã’ã¦æ˜ã‚‹ãã™ã‚‹ï¼‰ã‚’ã‚»ãƒƒãƒˆã—ã¦ã¿ã‚‹ã€€â€»æ’šç·šæ©Ÿã®ç”»è³ªæ”¹å–„ã®ãŸã‚
        ic.IC_SetPropertySwitch(hGrabber, tis.T("Tone Mapping"), tis.T("Enable"), 1)
        ic.IC_SetPropertySwitch(hGrabber, tis.T("Tone Mapping"), tis.T("Auto"), 0)
        ic.IC_SetPropertyAbsoluteValue(hGrabber, tis.T("Tone Mapping"), tis.T("Intensity"), 
                                       ctypes.c_float(float(p_dict['Intensity'])))
        ic.IC_SetPropertyAbsoluteValue(hGrabber, tis.T("Tone Mapping"), tis.T("Global Brightness Factor"), 
                                       ctypes.c_float(float(p_dict['GlobalBrightnessFactor'])))
    else:
        ic.IC_SetPropertySwitch(hGrabber, tis.T("Tone Mapping"), tis.T("Enable"), 0) #WDRç„¡åŠ¹

    if 'Gamma' in p_dict:
        #Gamma: 0.1-5.0 default 1.0
        ic.IC_SetPropertyAbsoluteValue(hGrabber, tis.T("Gamma"), tis.T("Value"),
                                       ctypes.c_float(float(p_dict['Gamma'])))

    if 'FPS' in p_dict:
        # fps: - 549
        ic.IC_SetFrameRate(hGrabber, ctypes.c_float(float(p_dict['FPS'])))

    if 'Exposure' in p_dict:
        # Exposure ï¼š0.000001 - 30.0
        ic.IC_SetPropertySwitch(hGrabber, tis.T("Exposure"), tis.T("Auto"), 0)
        ic.IC_SetPropertyAbsoluteValue(hGrabber, tis.T("Exposure"), tis.T("Value"), 
                                       ctypes.c_float(float(p_dict['Exposure'])))
    else:
        ic.IC_SetPropertySwitch(hGrabber, tis.T("Exposure"), tis.T("Auto"), 1) #Auto

    if 'Brightness' in p_dict:
        #Brightness : 0 - 4095 Default 240
        ic.IC_SetPropertyValue(hGrabber, tis.T("Brightness"), tis.T("Value"),
                               ctypes.c_int(int(p_dict['Brightness'])))

    if 'Gain' in p_dict:
        #Gain :0.0 - 48.0 Default 1.0
        ic.IC_SetPropertySwitch(hGrabber, tis.T("Gain"), tis.T("Auto"), 0)
        ic.IC_SetPropertyAbsoluteValue(hGrabber, tis.T("Gain"), tis.T("Value"), 
                                       ctypes.c_float(float(p_dict['Gain'])))
    else:
        ic.IC_SetPropertySwitch(hGrabber, tis.T("Gain"), tis.T("Auto"), 1) #Auto

    if 'WhiteBalanceRed' in p_dict and 'WhiteBalanceGreen' in p_dict and 'WhiteBalanceBlue' in p_dict:
        #WhiteBalance ï¼š å„è‰² 0.0 - 3.984375 â€»IC Captureãªã©ã§å®Ÿå†™ã‚’è¦‹ã¦èª¿æ•´
        ic.IC_SetPropertySwitch(hGrabber, tis.T("WhiteBalance"), tis.T("Auto"), 0)
        ic.IC_SetPropertyAbsoluteValue(hGrabber, tis.T("WhiteBalance"), tis.T("White Balance Red"), 
                                       ctypes.c_float(float(p_dict['WhiteBalanceRed'])))
        ic.IC_SetPropertyAbsoluteValue(hGrabber, tis.T("WhiteBalance"), tis.T("White Balance Green"), 
                                       ctypes.c_float(float(p_dict['WhiteBalanceGreen'])))              
        ic.IC_SetPropertyAbsoluteValue(hGrabber, tis.T("WhiteBalance"), tis.T("White Balance Blue"), 
                                       ctypes.c_float(float(p_dict['WhiteBalanceBlue'])))
    else:
        ic.IC_SetPropertySwitch(hGrabber, tis.T("WhiteBalance"), tis.T("Auto"), 1) #Auto
    return

class LoadT4TISCams:
    # Tile
    def __init__(self, sources='T4TISCams.txt', img_size=640, stride=32, auto=True):
        torch.backends.cudnn.benchmark = True  # faster for fixed-size inference æœ€æ–°ã®stream_loader.pyã‹ã‚‰ç™»ç”¨
        self.img_size = img_size
        self.stride = stride
        self.flag = True
        self.rbt_flag = False # ãƒ‡ãƒã‚¤ã‚¹ãƒ­ã‚¹ãƒˆãªã©ã§è‡ªå‹•çš„ã«è‡ªåˆ†ã‚’æ­¢ã‚ã‚‹ï¼ˆå†èµ·å‹•è¦å¦ã®ç›®å°ï¼‰ãƒ•ãƒ©ã‚°
        self.bubun = 40 # å‰ã¨æ–°ã—ã„ç”»åƒã®æ¯”è¼ƒã«ä½¿ã†å››è§’å½¢éƒ¨åˆ†ã®ä¸€è¾ºã®ãƒ”ã‚¯ã‚»ãƒ«æ•° â˜…å¿…ãšå¶æ•°ã«ã™ã‚‹ã“ã¨ï¼ï¼ï¼
        self.bad_cam = "" # ãƒ‡ãƒã‚¤ã‚¹ãƒ­ã‚¹ãƒˆã—ãŸã‚«ãƒ¡ãƒ©ã®ä½ç½®æƒ…å ±ã‚’æ¸¡ã™å¤‰æ•°

        if os.path.isfile(sources):
            with codecs.open(sources, 'r', 'utf-8') as f:
                sources = [x.strip() for x in f.read().strip().splitlines() if len(x.strip()) and x[0] != '#']
        else:
            sources = [sources]

        print(sources)
        n = len(sources)
        try:
            # TISã‚«ãƒ¡ãƒ©ã®ãŸã‚ã«importã™ã‚‹
            import ctypes
            import tisgrabber as tis
        except:
            print('tisgrabber.py,ã€€tisgrabber_x64.dll ãªã©å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ ã”ç¢ºèªãã ã•ã„!')
            sys.exit(0)
        self.imgs, self.frames, self.threads = [None] * 4, [0] * n, [None] * n
        self.sources = [clean_str(x) for x in sources]  # clean source names for later
        self.auto = auto

        self.cnt = 0 # maenoã¨nowã®åŒä¸€ç”»åƒæ¤œå‡ºã®å›æ•°ã‚«ã‚¦ãƒ³ã‚¿
        self.maeno = [None] * 4 # æ¯”è¼ƒç”¨ç”»åƒã‚’ä¿å­˜ã™ã‚‹å¤‰æ•°
        self.now = [None] * 4
        self.camset = [None] * 4 # ã‚«ãƒ¡ãƒ©å€‹åˆ¥è¨­å®šç”¨è¾æ›¸ã‚’èª­è¾¼ã‚€å¤‰æ•°ã€‚åˆæœŸã¯Noneã¨ã—ã¦åˆ¤æ–­ã«ä½¿ã†ã€‚

        self.fps = 70
        self.w = 640
        self.h = 480 # temporary definition
        vformat = "RGB24 ({0}x{1})".format(self.w, self.h) # ã‚«ãƒ¡ãƒ©ã®ãƒ“ãƒ‡ã‚ªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’æŒ‡å®šã™ã‚‹å®šæ•°
        self.obi = np.full((20, self.w, 3), (255, 255, 255), dtype=np.uint8) # å‹•ç”»æƒ…å ±ã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã®å¸¯
        self.top_obi = self.obi.copy()
        self.top_obi[0:20, 0:20] = (0, 0, 255) # ä¸Šã®ã‚ªãƒ“ã¯å·¦ç«¯ã‚’èµ¤ã«ã—ã¦ãƒ—ãƒ­ã‚°ãƒ©ãƒ åœæ­¢ã®ã‚¯ãƒªãƒƒã‚¯ã®ç›®å°ã¨ã™ã‚‹ã€‚
        for i, s in enumerate(sources):  # index, source
            # åˆã‚ã«ç”»åƒæ¯”è¼ƒç”¨ã®å‰ã®ç”»åƒã«å½“ãŸã‚‹ã‚‚ã®ã‚’ç”¨æ„ã—ã¦ãŠã
            self.now[i] = np.full((self.bubun, self.bubun, 3), (0, 0, 255), dtype=np.uint8)
            self.maeno[i] = np.full((self.bubun, self.bubun, 3), (0, 255, 0), dtype=np.uint8)
            # ã‚«ãƒ¡ãƒ©ã®ç«‹ä¸Šã‚Šé †ã«ã‚ˆã‚‹ã‚¨ãƒ©ãƒ¼ã‚’å›é¿ã™ã‚‹ãŸã‚ã«äºˆã‚èµ¤è‰²ã®ç”»é¢ã‚’ã‚«ãƒ¡ãƒ©ã®æ•°ã ã‘ç”¨æ„ã—ã¦ãŠã
            self.imgs[i] = np.full((self.h, self.w, 3), (0, 0, 255), dtype=np.uint8)
            # ã‚«ãƒ¡ãƒ©ç«‹ä¸Šã’ã®ãƒ«ãƒ¼ãƒ—ã®å‰ã«è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®æœ‰ç„¡ã‚’ç¢ºèªã—ã¦ã€ã‚ã‚‰ã‹ã˜ã‚å–è¾¼ã‚“ã§ãŠã
            sn = s.split()[-1] # 'DFK 37BUX287 11223344' ã‚’åˆ†å‰²ã—ã¦æœ€å¾Œã®S/Nã®ã¿å–ã‚Šå‡ºã—
            if os.path.exists(sn + '.txt'): # å€‹åˆ¥ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã£ãŸã‚‰
                print(f'{i}ç•ªã‚«ãƒ¡ãƒ©ï¼šS/N{sn}ã€€ã®è¨­å®šãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚å€‹åˆ¥è¨­å®šã—ã¾ã™ã€‚', end = '')
                self.camset[i] = get_camera_params(sn)
                print(f'{i} Done !')

        self.ic = ctypes.cdll.LoadLibrary("./tisgrabber_x64.dll") # TISãŠã¾ã˜ãªã„1
        tis.declareFunctions(self.ic) # TISãŠã¾ã˜ãªã„2
        self.ic.IC_InitLibrary(0) # TISãŠã¾ã˜ãªã„3
        self.hGrabber = [None] * 4 # ã‚«ãƒ¡ãƒ©ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆã‚’å®šç¾©ã—ã¦ãŠã

        for i, s in enumerate(sources):  # index, source
            self.frames[i] = float('inf')  # infinite stream fallback
            # Start thread to read frames from video stream
            st = f'{i + 1}/{n}: {s}... '
            s = str(s)
            self.hGrabber[i] = self.ic.IC_CreateGrabber()
            self.ic.IC_OpenDevByUniqueName(self.hGrabber[i], tis.T(s)) # ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼ã®æŒ‡å®šã‚‚å¯èƒ½
            self.ic.IC_SetVideoFormat(self.hGrabber[i], tis.T(vformat))
            if (self.ic.IC_IsDevValid(self.hGrabber[i])): # ã‚«ãƒ¡ãƒ©ãŒé–‹ã‘ãŸã‚‰
                if self.camset[i] != None: # å€‹åˆ¥ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šãŒNoneã§ãªã‘ã‚Œã°
                    p_dict = self.camset[i]
                else:
                    # å€‹åˆ¥ã«æŒ‡å®šã—ãªã„ã¨ãã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æŒ‡å®š IC Captureãªã©ã§å®Ÿå†™ã‚’è¦‹ã¦èª¿æ•´
                    p_dict = {'FPS': '80',
                              'Exposure': '0.004',
                              'Brightness': '240',
                              'Gain': '0.0',
                              'WhiteBalanceRed': '1.66',
                              'WhiteBalanceGreen': '1.00', 
                              'WhiteBalanceBlue': '2.48',
                              #'Gamma': '0.7',
                              #'Intensity': '0.5', 
                              #'GlobalBrightnessFactor': '0.0',
                              #'ex':'ä½¿ã‚ãªã„ã¨ã“ã‚ã¯#ã§ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆå¯èƒ½',
                             }
                set_camera_params(p_dict, i, self.hGrabber[i], self.ic, ctypes, tis)
                
                # Start the live video stream, but show no own live video window. We will use OpenCV for this.
                self.ic.IC_StartLive(self.hGrabber[i], 0) # å¼•æ•°ã‚’ã€Œï¼‘ã€ã«ã™ã‚‹ã¨ãƒ©ã‚¤ãƒ–ç”»åƒãŒé–‹ãã€‚OpenCVã§ã®æç”»ã‚’ã™ã‚‹ã®ã§ã€Œï¼ã€ã¨ã™ã‚‹ã€‚
                #print('â˜…â˜…ic.IC_SnapImage(hGrabber[',i, ']: ', ic.IC_SnapImage(hGrabber[i])) #debugprint

                # é€£ç¶šå–ã‚Šè¾¼ã¿ã®ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’èµ·å‹•ã™ã‚‹
                self.threads[i] = Thread(target=self.update, args=([i, self.hGrabber[i], s, self.ic, ctypes, tis]), daemon=True)
                self.threads[i].start()
                print(f"{st} Success ({self.frames[i]} frames {self.w}x{self.h} at {float(p_dict['FPS']):.2f} FPS)")

            else: # ã‚«ãƒ¡ãƒ©ãŒé–‹ã‘ãªã„æ™‚
                print(f'{st}Failed to open Cam {s}')
                self.ic.IC_CloseVideoCaptureDevice(self.hGrabber[i])
                self.ic.IC_ReleaseGrabber(self.hGrabber[i]) 
        self.rect = True  # dummy code. rect inference if all shapes equal

    def update(self, i, hGrabber, stream, ic, ctypes, tis):
        Width = ctypes.c_long()
        Height = ctypes.c_long()
        BitsPerPixel = ctypes.c_int()
        colorformat = ctypes.c_int()
        cnt_a = 0 # ç”»åƒãŒå–è¾¼ã‚ãªã‹ã£ãŸé€£ç¶šå›æ•°ã®ã‚«ã‚¦ãƒ³ã‚¿
        while (self.ic.IC_IsDevValid(hGrabber)) and self.flag:
            # ã‹ãªã‚Šé•·ã„è¨˜è¿°ã«ãªã‚‹ãŒä»¥ä¸‹self.imgs[i] = im ã¾ã§ã§ç”»åƒã‚’OpenCVã«æ¸¡ã›ã‚‹å½¢ã§å–å¾—ã—ã¦ã„ã‚‹
            if self.ic.IC_SnapImage(hGrabber) == tis.IC_SUCCESS:
                # Query values of image description
                self.ic.IC_GetImageDescription(hGrabber, Width, Height, BitsPerPixel, colorformat)
                # Calculate the buffer size
                bpp = int(BitsPerPixel.value / 8.0)
                buffer_size = Width.value * Height.value * BitsPerPixel.value
                imagePtr = self.ic.IC_GetImagePtr(hGrabber)
                imagedata = ctypes.cast(imagePtr, ctypes.POINTER(ctypes.c_ubyte * buffer_size))
                # Create the numpy array
                im = np.ndarray(buffer=imagedata.contents, dtype=np.uint8, shape=(Height.value, Width.value, bpp))
                im = cv2.flip(im, 0)
                self.imgs[i] = im
                cnt_a = 0
                #time.sleep(1 / self.fps)  # wait timeã¯TISã‚«ãƒ¡ãƒ©ã§ã¯ä¸è¦

            else: # ç”»åƒãŒä¸Šæ‰‹ãå–ã‚Šè¾¼ã‚ãªã‹ã£ãŸã¨ãã®å‡¦ç†ã€‚
                # ç”£æ¥­ç”¨ã‚«ãƒ¡ãƒ©ã§ã‚‚å¿…ãšç”»åƒã®å–ã‚Šã“ã¼ã—ãŒèµ·ãã‚‹ã®ã§ä¸€åº¦ã‚„äºŒåº¦ã§æ­¢ã‚ã¦ã¯ã„ã‘ãªã„ã€‚ã“ã“ã§ã¯10å›é€£ç¶šã§ç•°å¸¸ã¨åˆ¤æ–­ã™ã‚‹ã€‚
                print(f'WARNING: Cam{i} ç”»åƒãŒæ­£å¸¸ã«å–è¾¼ã‚ã¦ã„ã¾ã›ã‚“ã€‚')
                cnt_a += 1
                self.imgs[i] =  np.full((self.h, self.w, 3), (98, 244, 255), dtype=np.uint8) # é»„è‰²ã„ç”»åƒã«ã™ã‚‹
                if cnt_a >= 10: # ç”»åƒãŒæ­£å¸¸ã«å–ã‚Šè¾¼ã‚ãªã„çŠ¶æ…‹ãŒ10å›ç¶šã„ãŸã‚‰ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹
                    print(f'Cam{i} ç”»åƒãŒå–è¾¼ã‚ãªã„çŠ¶æ…‹ãŒ{cnt_a}ãƒ«ãƒ¼ãƒ—ç¶šã„ãŸã®ã§ãƒ«ãƒ¼ãƒ—ã‹ã‚‰æŠœã‘ã¾ã™ã€‚')
                    break

        # ä½•ã‚‰ã‹ã®ç†ç”±ã§ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã¦ã—ã¾ã£ãŸå ´åˆã‚‚ãƒ–ãƒ«ãƒ¼ãƒãƒƒã‚¯ç”»åƒã¨ã™ã‚‹ã€‚ã“ã“ã«æ¥ã‚‹ã®ã¯Escã§æ„è­˜çš„ã«æ­¢ã‚ãŸæ™‚ã¨ic.IC_IsDevValid(hGrabber)ãŒFalseã®æ™‚+ic.IC_SnapImage(hGrabber) == tis.IC_SUCCESSã§ãªã„æ™‚ã€‚
        self.imgs[i] =  np.full((self.h, self.w, 3), (255, 0, 0), dtype=np.uint8)        
        self.ic.IC_StopLive(hGrabber)
        self.ic.IC_CloseVideoCaptureDevice(hGrabber)
        self.ic.IC_ReleaseGrabber(hGrabber)        
        print('ç”»åƒå–è¾¼ã®ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã¾ã—ãŸã€‚ Cam:', i)
        return

    def __iter__(self):
        return self

    def __next__(self):
        ky = cv2.waitKey(1)
        if ky == 27 or self.rbt_flag: # esc to quit 
            self.flag = False
            cv2.destroyAllWindows()
            if ky == 27:
                print('ã‚­ãƒ¼å…¥åŠ›ã«ã‚ˆã‚Šåœæ­¢ã—ã¾ã—ãŸã€‚')
            #time.sleep(1) # ã‚«ãƒ¡ãƒ©ã‚¹ãƒ¬ãƒƒãƒ‰ã®çµ‚äº†å¾…ã¡
            self.ic.IC_CloseLibrary()
            raise StopIteration
        if not self.flag:
            self.ic.IC_CloseLibrary()
            raise StopIteration

        self.now[0] = self.imgs[0][int(self.h/2) - int(self.bubun/2):int(self.h/2) + int(self.bubun/2), int(self.w/2) - int(self.bubun/2):int(self.w/2) + int(self.bubun/2)]
        self.now[1] = self.imgs[1][int(self.h/2) - int(self.bubun/2):int(self.h/2) + int(self.bubun/2), int(self.w/2) - int(self.bubun/2):int(self.w/2) + int(self.bubun/2)]   
        self.now[2] = self.imgs[2][int(self.h/2) - int(self.bubun/2):int(self.h/2) + int(self.bubun/2), int(self.w/2) - int(self.bubun/2):int(self.w/2) + int(self.bubun/2)]
        self.now[3] = self.imgs[3][int(self.h/2) - int(self.bubun/2):int(self.h/2) + int(self.bubun/2), int(self.w/2) - int(self.bubun/2):int(self.w/2) + int(self.bubun/2)] 

        if (self.now[0] == self.maeno[0]).all() or (self.now[1] == self.maeno[1]).all() or (self.now[2] == self.maeno[2]).all() or (self.now[3] == self.maeno[3]).all():
            self.cnt +=1
            if self.cnt >= self.fps * 4 : # ç”»åƒãŒæ›´æ–°ã•ã‚Œãªã„ã¨ã„ã†åˆ¤æ–­ãŒæ•°ç§’ç¶šã„ãŸã‚‰â€¦
                self.flag = False
                if (self.now[0] == self.maeno[0]).all():
                    self.bad_cam = "å·¦ä¸Š"
                elif (self.now[1] == self.maeno[1]).all():
                    self.bad_cam = "å³ä¸Š"
                elif (self.now[2] == self.maeno[2]).all():
                    self.bad_cam = "å³ä¸‹"
                elif (self.now[3] == self.maeno[3]).all():
                    self.bad_cam = "å·¦ä¸‹"
                self.rbt_flag = True # çµ‚äº†å¾Œã€è‡ªåˆ†ã‚’å†èµ·å‹•ã™ã‚‹ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹
        else:
            self.cnt = 0 # æ¯”è¼ƒçµæœãŒç•°ãªã‚Œã°ã‚«ã‚¦ãƒ³ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ

        # ã“ã“ã§4ã¤ã®ç”»åƒã‚’åˆæˆã™ã‚‹
        self.concimg = cv2.hconcat([self.imgs[0], self.imgs[1]])
        conc2 = cv2.hconcat([self.imgs[3], self.imgs[2]])
        self.concimg = cv2.vconcat([self.concimg, conc2])
        self.concimg = cv2.resize(self.concimg, (self.w, self.h), interpolation = cv2.INTER_AREA)
        self.concimg = cv2.vconcat([self.top_obi, self.concimg, self.obi])
        #self.concimg = np.expand_dims(self.concimg, axis=0) # CHW > BCHW 

        self.maeno[0] = self.now[0] # æ¯”è¼ƒç”¨ç”»åƒã®å…¥ã‚Œæ›¿ãˆ
        self.maeno[1] = self.now[1] # æ¯”è¼ƒç”¨ç”»åƒã®å…¥ã‚Œæ›¿ãˆ
        self.maeno[2] = self.now[2] # æ¯”è¼ƒç”¨ç”»åƒã®å…¥ã‚Œæ›¿ãˆ
        self.maeno[3] = self.now[3] # æ¯”è¼ƒç”¨ç”»åƒã®å…¥ã‚Œæ›¿ãˆ

        img0 = self.concimg.copy()
        # Letterbox
        #img_lb = letterbox(img0)[0] # letterboxé–¢æ•°ã‹ã‚‰è¿”ã£ã¦ããŸç”»åƒéƒ¨åˆ†ã®ã¿
        img_lb = None # 202409ç¾åœ¨letterboxå‡¦ç†ã¯MultiBackendã«ä»»ã›ã‚‹ã®ã§â€¦

        return self.sources, img_lb, img0, self.rbt_flag, self.bad_cam

class LoadV4TISCams:
    # Vertical
    def __init__(self, sources='V4TISCams.txt', img_size=640, stride=32, auto=True):
        torch.backends.cudnn.benchmark = True  # faster for fixed-size inference æœ€æ–°ã®stream_loader.pyã‹ã‚‰ç™»ç”¨
        self.img_size = img_size
        self.stride = stride
        self.flag = True
        self.rbt_flag = False # ãƒ‡ãƒã‚¤ã‚¹ãƒ­ã‚¹ãƒˆãªã©ã§è‡ªå‹•çš„ã«è‡ªåˆ†ã‚’æ­¢ã‚ã‚‹ï¼ˆå†èµ·å‹•è¦å¦ã®ç›®å°ï¼‰ãƒ•ãƒ©ã‚°
        self.bubun = 40 # å‰ã¨æ–°ã—ã„ç”»åƒã®æ¯”è¼ƒã«ä½¿ã†å››è§’å½¢éƒ¨åˆ†ã®ä¸€è¾ºã®ãƒ”ã‚¯ã‚»ãƒ«æ•° â˜…å¿…ãšå¶æ•°ã«ã™ã‚‹ã“ã¨ï¼ï¼ï¼
        self.bad_cam = "" # ãƒ‡ãƒã‚¤ã‚¹ãƒ­ã‚¹ãƒˆã—ãŸã‚«ãƒ¡ãƒ©ã®ä½ç½®æƒ…å ±ã‚’æ¸¡ã™å¤‰æ•°

        if os.path.isfile(sources):
            with codecs.open(sources, 'r', 'utf-8') as f:
                sources = [x.strip() for x in f.read().strip().splitlines() if len(x.strip()) and x[0] != '#']
        else:
            sources = [sources]

        print(sources)
        n = len(sources)
        try:
            # TISã‚«ãƒ¡ãƒ©ã®ãŸã‚ã«importã™ã‚‹
            import ctypes
            import tisgrabber as tis
        except:
            print('tisgrabber.py,ã€€tisgrabber_x64.dll ãªã©å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ ã”ç¢ºèªãã ã•ã„!')
            sys.exit(0)
        self.imgs, self.frames, self.threads = [None] * 4, [0] * n, [None] * n
        self.sources = [clean_str(x) for x in sources]  # clean source names for later
        self.auto = auto

        self.cnt = 0 # maenoã¨nowã®åŒä¸€ç”»åƒæ¤œå‡ºã®å›æ•°ã‚«ã‚¦ãƒ³ã‚¿
        self.maeno = [None] * 4 # æ¯”è¼ƒç”¨ç”»åƒã‚’ä¿å­˜ã™ã‚‹å¤‰æ•°
        self.now = [None] * 4
        self.camset = [None] * 4 # ã‚«ãƒ¡ãƒ©å€‹åˆ¥è¨­å®šç”¨è¾æ›¸ã‚’èª­è¾¼ã‚€å¤‰æ•°ã€‚åˆæœŸã¯Noneã¨ã—ã¦åˆ¤æ–­ã«ä½¿ã†ã€‚

        self.fps = 80
        self.w = 720 #640
        self.h = 180 #160
        vformat = "RGB24 ({0}x{1})".format(self.w, self.h) # ã‚«ãƒ¡ãƒ©ã®ãƒ“ãƒ‡ã‚ªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        self.obi = np.full((20, self.w, 3), (255, 255, 255), dtype=np.uint8) # å‹•ç”»æƒ…å ±ã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã®å¸¯
        self.top_obi = self.obi.copy()
        self.top_obi[0:20, 0:20] = (0, 0, 255) # ä¸Šã®ã‚ªãƒ“ã¯å·¦ç«¯ã‚’èµ¤ã«ã—ã¦ãƒ—ãƒ­ã‚°ãƒ©ãƒ åœæ­¢ã®ã‚¯ãƒªãƒƒã‚¯ã®ç›®å°ã¨ã™ã‚‹ã€‚
        for i, s in enumerate(sources):
            # åˆã‚ã«ç”»åƒæ¯”è¼ƒç”¨ã®å‰ã®ç”»åƒã«å½“ãŸã‚‹ã‚‚ã®ã‚’ç”¨æ„ã—ã¦ãŠã
            self.now[i] = np.full((self.bubun, self.bubun, 3), (0, 0, 255), dtype=np.uint8)
            self.maeno[i] = np.full((self.bubun, self.bubun, 3), (0, 255, 0), dtype=np.uint8)
            # ã‚«ãƒ¡ãƒ©ã®ç«‹ä¸Šã‚Šé †ã«ã‚ˆã‚‹ã‚¨ãƒ©ãƒ¼ã‚’å›é¿ã™ã‚‹ãŸã‚ã«äºˆã‚èµ¤è‰²ã®ç”»é¢ã‚’ã‚«ãƒ¡ãƒ©ã®æ•°ã ã‘ç”¨æ„ã—ã¦ãŠã
            self.imgs[i] = np.full((self.h, self.w, 3), (0, 0, 255), dtype=np.uint8)
            # ã‚«ãƒ¡ãƒ©ç«‹ä¸Šã’ã®ãƒ«ãƒ¼ãƒ—ã®å‰ã«è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®æœ‰ç„¡ã‚’ç¢ºèªã—ã¦ã€ã‚ã‚‰ã‹ã˜ã‚å–è¾¼ã‚“ã§ãŠã
            sn = s.split()[-1] # 'DFK 37BUX287 11223344' ã‚’åˆ†å‰²ã—ã¦æœ€å¾Œã®S/Nã®ã¿å–ã‚Šå‡ºã—
            if os.path.exists(sn + '.txt'): # å€‹åˆ¥ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã£ãŸã‚‰
                print(f'{i}ç•ªã‚«ãƒ¡ãƒ©ï¼šS/N{sn}ã€€ã®è¨­å®šãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚å€‹åˆ¥è¨­å®šã—ã¾ã™ã€‚', end = '')
                self.camset[i] = get_camera_params(sn)
                print(f'{i} Done !')

        self.ic = ctypes.cdll.LoadLibrary("./tisgrabber_x64.dll") # TISãŠã¾ã˜ãªã„1
        tis.declareFunctions(self.ic) # TISãŠã¾ã˜ãªã„2
        self.ic.IC_InitLibrary(0) # TISãŠã¾ã˜ãªã„3
        self.hGrabber = [None] * 4 # ã‚«ãƒ¡ãƒ©ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆã‚’å®šç¾©ã—ã¦ãŠã

        for i, s in enumerate(sources):  # index, source
            self.frames[i] = float('inf')  # infinite stream fallback
            # Start thread to read frames from video stream
            st = f'Cam {i}: {s}... '
            s = str(s)
            self.hGrabber[i] = self.ic.IC_CreateGrabber()
            self.ic.IC_OpenDevByUniqueName(self.hGrabber[i], tis.T(s)) # ã‚·ãƒªã‚¢ãƒ«ãƒŠãƒ³ãƒãƒ¼ã®æŒ‡å®šã‚‚å¯èƒ½
            self.ic.IC_SetVideoFormat(self.hGrabber[i], tis.T(vformat))
            if (self.ic.IC_IsDevValid(self.hGrabber[i])): # ã‚«ãƒ¡ãƒ©ãŒé–‹ã‘ãŸã‚‰
                if self.camset[i] != None: # å€‹åˆ¥ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šãŒNoneã§ãªã‘ã‚Œã°
                    p_dict = self.camset[i]
                else:
                    # å€‹åˆ¥ã«æŒ‡å®šã—ãªã„ã¨ãã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æŒ‡å®š IC Captureãªã©ã§å®Ÿå†™ã‚’è¦‹ã¦èª¿æ•´
                    p_dict = {'FPS': '80',
                              'Exposure': '0.004',
                              'Brightness': '240',
                              'Gain': '25.0',
                              'WhiteBalanceRed': '1.66',
                              'WhiteBalanceGreen': '1.00', 
                              'WhiteBalanceBlue': '2.48',
                              'Gamma': '0.7',
                              'Intensity': '0.5', 
                              'GlobalBrightnessFactor': '0.0',
                              #'ex':'ä½¿ã‚ãªã„ã¨ã“ã‚ã¯#ã§ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆå¯èƒ½',
                             }
                set_camera_params(p_dict, i, self.hGrabber[i], self.ic, ctypes, tis)

                # Start the live video stream, but show no own live video window. We will use OpenCV for this.
                self.ic.IC_StartLive(self.hGrabber[i], 0) # å¼•æ•°ã‚’ã€Œï¼‘ã€ã«ã™ã‚‹ã¨ãƒ©ã‚¤ãƒ–ç”»åƒãŒé–‹ãã€‚OpenCVã§ã®æç”»ã‚’ã™ã‚‹ã®ã§ã€Œï¼ã€ã¨ã™ã‚‹ã€‚
                #print('â˜…â˜…ic.IC_SnapImage(hGrabber[',i, ']: ', ic.IC_SnapImage(hGrabber[i])) #debugprint

                # é€£ç¶šå–ã‚Šè¾¼ã¿ã®ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’èµ·å‹•ã™ã‚‹
                self.threads[i] = Thread(target=self.update, args=([i, self.hGrabber[i], s, self.ic, ctypes, tis]), daemon=True)
                self.threads[i].start()
                print(f"{st} Success ({self.frames[i]} frames {self.w}x{self.h} at {float(p_dict['FPS']):.2f} FPS)")

            else: # ã‚«ãƒ¡ãƒ©ãŒé–‹ã‘ãªã„æ™‚
                print(f'{st}Failed to open Cam {s}')
                self.ic.IC_CloseVideoCaptureDevice(self.hGrabber[i])
                self.ic.IC_ReleaseGrabber(self.hGrabber[i])
        self.rect = True  # dummy code. rect inference if all shapes equal

    def update(self, i, hGrabber, stream, ic, ctypes, tis):
        Width = ctypes.c_long()
        Height = ctypes.c_long()
        BitsPerPixel = ctypes.c_int()
        colorformat = ctypes.c_int()
        cnt_a = 0 # ç”»åƒãŒå–è¾¼ã‚ãªã‹ã£ãŸé€£ç¶šå›æ•°ã®ã‚«ã‚¦ãƒ³ã‚¿
        while (self.ic.IC_IsDevValid(hGrabber)) and self.flag:
            # ã‹ãªã‚Šé•·ã„è¨˜è¿°ã«ãªã‚‹ãŒä»¥ä¸‹self.imgs[i] = im ã¾ã§ã§ç”»åƒã‚’OpenCVã«æ¸¡ã›ã‚‹å½¢ã§å–å¾—ã—ã¦ã„ã‚‹
            if self.ic.IC_SnapImage(hGrabber) == tis.IC_SUCCESS:
                # Query values of image description
                self.ic.IC_GetImageDescription(hGrabber, Width, Height, BitsPerPixel, colorformat)
                # Calculate the buffer size
                bpp = int(BitsPerPixel.value / 8.0)
                buffer_size = Width.value * Height.value * BitsPerPixel.value
                imagePtr = self.ic.IC_GetImagePtr(hGrabber)
                imagedata = ctypes.cast(imagePtr, ctypes.POINTER(ctypes.c_ubyte * buffer_size))
                # Create the numpy array
                im = np.ndarray(buffer=imagedata.contents, dtype=np.uint8, shape=(Height.value, Width.value, bpp))
                im = cv2.flip(im, 0)
                self.imgs[i] = im
                cnt_a = 0
                #time.sleep(1 / self.fps)  # wait timeã¯TISã‚«ãƒ¡ãƒ©ã§ã¯ä¸è¦

            else: # ç”»åƒãŒä¸Šæ‰‹ãå–ã‚Šè¾¼ã‚ãªã‹ã£ãŸã¨ãã®å‡¦ç†ã€‚
                # ç”£æ¥­ç”¨ã‚«ãƒ¡ãƒ©ã§ã‚‚å¿…ãšç”»åƒã®å–ã‚Šã“ã¼ã—ãŒèµ·ãã‚‹ã®ã§ä¸€åº¦ã‚„äºŒåº¦ã§æ­¢ã‚ã¦ã¯ã„ã‘ãªã„ã€‚ã“ã“ã§ã¯10å›é€£ç¶šã§ç•°å¸¸ã¨åˆ¤æ–­ã™ã‚‹ã€‚
                print(f'WARNING: Cam{i} ç”»åƒãŒæ­£å¸¸ã«å–è¾¼ã‚ã¦ã„ã¾ã›ã‚“ã€‚')
                cnt_a += 1
                self.imgs[i] =  np.full((self.h, self.w, 3), (98, 244, 255), dtype=np.uint8) # é»„è‰²ã„ç”»åƒã«ã™ã‚‹
                if cnt_a >= 10: # ç”»åƒãŒæ­£å¸¸ã«å–ã‚Šè¾¼ã‚ãªã„çŠ¶æ…‹ãŒ10å›ç¶šã„ãŸã‚‰ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹
                    print(f'Cam{i} ç”»åƒãŒå–è¾¼ã‚ãªã„çŠ¶æ…‹ãŒ{cnt_a}ãƒ«ãƒ¼ãƒ—ç¶šã„ãŸã®ã§ãƒ«ãƒ¼ãƒ—ã‹ã‚‰æŠœã‘ã¾ã™ã€‚')
                    break

        # ä½•ã‚‰ã‹ã®ç†ç”±ã§ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã¦ã—ã¾ã£ãŸå ´åˆã‚‚ãƒ–ãƒ«ãƒ¼ãƒãƒƒã‚¯ç”»åƒã¨ã™ã‚‹ã€‚ã“ã“ã«æ¥ã‚‹ã®ã¯Escã§æ„è­˜çš„ã«æ­¢ã‚ãŸæ™‚ã¨ic.IC_IsDevValid(hGrabber)ãŒFalseã®æ™‚+ic.IC_SnapImage(hGrabber) == tis.IC_SUCCESSã§ãªã„æ™‚ã€‚
        self.imgs[i] =  np.full((self.h, self.w, 3), (255, 0, 0), dtype=np.uint8) # é’ã„ç”»åƒã«ã™ã‚‹
        self.ic.IC_StopLive(hGrabber)
        self.ic.IC_CloseVideoCaptureDevice(hGrabber)
        self.ic.IC_ReleaseGrabber(hGrabber)
        print('ç”»åƒå–è¾¼ã®ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã¾ã—ãŸã€‚ Cam:', i)
        return

    def __iter__(self):
        return self

    def __next__(self):
        ky = cv2.waitKey(1)
        if ky == 27 or self.rbt_flag: # esc to quit 
            self.flag = False
            cv2.destroyAllWindows()
            if ky == 27:
                print('ã‚­ãƒ¼å…¥åŠ›ã«ã‚ˆã‚Šåœæ­¢ã—ã¾ã—ãŸã€‚')
            #time.sleep(1) # ã‚«ãƒ¡ãƒ©ã‚¹ãƒ¬ãƒƒãƒ‰ã®çµ‚äº†å¾…ã¡
            self.ic.IC_CloseLibrary()
            raise StopIteration
        if not self.flag:
            self.ic.IC_CloseLibrary()
            raise StopIteration

        # æ¯”è¼ƒç”¨ç”»åƒã®åˆ‡ã‚Šå‡ºã—
        self.now[0] = self.imgs[0][int(self.h/2) - int(self.bubun/2):int(self.h/2) + int(self.bubun/2), int(self.w/2) - int(self.bubun/2):int(self.w/2) + int(self.bubun/2)]
        self.now[1] = self.imgs[1][int(self.h/2) - int(self.bubun/2):int(self.h/2) + int(self.bubun/2), int(self.w/2) - int(self.bubun/2):int(self.w/2) + int(self.bubun/2)]   
        self.now[2] = self.imgs[2][int(self.h/2) - int(self.bubun/2):int(self.h/2) + int(self.bubun/2), int(self.w/2) - int(self.bubun/2):int(self.w/2) + int(self.bubun/2)]
        self.now[3] = self.imgs[3][int(self.h/2) - int(self.bubun/2):int(self.h/2) + int(self.bubun/2), int(self.w/2) - int(self.bubun/2):int(self.w/2) + int(self.bubun/2)] 
        
        if (self.now[0] == self.maeno[0]).all() or (self.now[1] == self.maeno[1]).all() or (self.now[2] == self.maeno[2]).all() or (self.now[3] == self.maeno[3]).all():
            self.cnt +=1
            if self.cnt >= self.fps * 4 : # ç”»åƒãŒæ›´æ–°ã•ã‚Œãªã„ã¨ã„ã†åˆ¤æ–­ãŒæ•°ç§’ç¶šã„ãŸã‚‰â€¦
                self.flag = False
                if (self.now[0] == self.maeno[0]).all():
                    self.bad_cam = "ä¸€ç•ªä¸Š"
                elif (self.now[1] == self.maeno[1]).all():
                    self.bad_cam = "äºŒç•ªç›®"
                elif (self.now[2] == self.maeno[2]).all():
                    self.bad_cam = "ä¸‰ç•ªç›®"
                elif (self.now[3] == self.maeno[3]).all():
                    self.bad_cam = "ä¸€ç•ªä¸‹"
                self.rbt_flag = True # çµ‚äº†å¾Œã€è‡ªåˆ†ã‚’å†èµ·å‹•ã™ã‚‹ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹
        else:
            self.cnt = 0 # æ¯”è¼ƒçµæœãŒç•°ãªã‚Œã°ã‚«ã‚¦ãƒ³ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ

        # ã“ã“ã§4ã¤ã®ç”»åƒã‚’åˆæˆã™ã‚‹
        self.concimg = cv2.vconcat([self.top_obi, self.imgs[0], self.imgs[1],self.imgs[2], self.imgs[3], self.obi]) # ç¸¦ç©ã¿ãªã‚‰ä¸€åº¦ã§vconcatå‡ºæ¥ã‚‹ã€‚

        self.maeno[0] = self.now[0] # æ¯”è¼ƒç”¨ç”»åƒã®å…¥ã‚Œæ›¿ãˆ
        self.maeno[1] = self.now[1] # æ¯”è¼ƒç”¨ç”»åƒã®å…¥ã‚Œæ›¿ãˆ
        self.maeno[2] = self.now[2] # æ¯”è¼ƒç”¨ç”»åƒã®å…¥ã‚Œæ›¿ãˆ
        self.maeno[3] = self.now[3] # æ¯”è¼ƒç”¨ç”»åƒã®å…¥ã‚Œæ›¿ãˆ

        img0 = self.concimg.copy()
        # Letterbox
        #img_lb = letterbox(img0)[0] # letterboxé–¢æ•°ã‹ã‚‰è¿”ã£ã¦ããŸç”»åƒéƒ¨åˆ†ã®ã¿
        img_lb = None # 202409ç¾åœ¨letterboxå‡¦ç†ã¯MultiBackendã«ä»»ã›ã‚‹ã®ã§â€¦

        return self.sources, img_lb, img0, self.rbt_flag, self.bad_cam

class LoadT4Streams:
    # for USB camera  Tile
    def __init__(self, sources='streams.txt', img_size=640, stride=32, auto=True):
        global flag
        self.img_size = img_size
        self.stride = stride
        self.flag = True # è¤‡æ•°é–‹ã„ãŸã‚«ãƒ¡ãƒ©ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‰ã˜ã‚‹ãŸã‚ã®ãƒ•ãƒ©ã‚°
        self.rbt_flag = False # ãƒ‡ãƒã‚¤ã‚¹ãƒ­ã‚¹ãƒˆãªã©ã§è‡ªå‹•çš„ã«è‡ªåˆ†ã‚’æ­¢ã‚ã‚‹ï¼ˆå†èµ·å‹•è¦å¦ã®ç›®å°ï¼‰ãƒ•ãƒ©ã‚°
        self.bad_cam = "" # ãƒ‡ãƒã‚¤ã‚¹ãƒ­ã‚¹ãƒˆã—ãŸã‚«ãƒ¡ãƒ©ã®ä½ç½®æƒ…å ±ã‚’æ¸¡ã™å¤‰æ•°
        self.w = 640
        self.h = 480

        if os.path.isfile(sources):
            with codecs.open(sources, 'r', 'utf-8') as f:
                sources = [x.strip() for x in f.read().strip().splitlines() if len(x.strip()) and x[0] != '#']
        else:
            sources = [sources]

        print(sources)
        n = len(sources)
        self.imgs, self.fps, self.frames, self.threads = [None] * 4, [0] * n, [0] * n, [None] * n
        self.sources = [clean_str(x) for x in sources]  # clean source names for later
        self.auto = auto
        self.obi = np.full((20, self.w, 3), (255, 255, 255), dtype=np.uint8) # å‹•ç”»æƒ…å ±ã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã®å¸¯
        self.top_obi = self.obi.copy()
        self.top_obi[0:20, 0:20] = (0, 0, 255) # ä¸Šã®ã‚ªãƒ“ã¯å·¦ç«¯ã‚’èµ¤ã«ã—ã¦ãƒ—ãƒ­ã‚°ãƒ©ãƒ åœæ­¢ã®ã‚¯ãƒªãƒƒã‚¯ã®ç›®å°ã¨ã™ã‚‹ã€‚
        
        # ã‚«ãƒ¡ãƒ©ã®ç«‹ã¡ä¸ŠãŒã‚Šæ–¹æ¬¡ç¬¬ã§ã‚¨ãƒ©ãƒ¼ã‚’èµ·ã“ã™ã“ã¨ã‚ã‚‹ã®ã§ã€äºˆã‚èµ¤è‰²ã®ç”»é¢ã‚’ã‚«ãƒ¡ãƒ©ã®æ•°ã ã‘ç”¨æ„ã—ã¦ãŠã
        for i, s in enumerate(sources):  # index, source
            self.imgs[i] = np.full((self.h, self.w, 3), (0, 0, 255), dtype=np.uint8)

        for i, s in enumerate(sources):  # index, source
            # Start thread to read frames from video stream
            st = f'{i + 1}/{n}: {s}... '
            s = eval(s) if s.isnumeric() else s  # i.e. s = '0' local webcam
            cap = cv2.VideoCapture(s + cv2.CAP_DSHOW)
            #assert cap.isOpened(), f'{st}Failed to open {s}'
            w = self.w #int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            h = self.h #int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            self.fps[i] = max(cap.get(cv2.CAP_PROP_FPS) % 100, 0) or 30.0  # 30 FPS fallback
            self.frames[i] = max(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)), 0) or float('inf')  # infinite stream fallback

            if cap.isOpened():
                _, self.imgs[i] = cap.read()  # guarantee first frame
                self.threads[i] = Thread(target=self.update, args=([i, cap, s]), daemon=False)
                # threadsã¯ã€daemon=Trueã§è¤‡æ•°èµ·å‹•ã™ã‚‹ã¨çµ‚äº†æ™‚ã«ã‚«ãƒ¡ãƒ©ã‚’é–‹æ”¾ã—ãªããªã‚‹ã€‚ãã®ãŸã‚daemon=Falseï¼ˆãƒ‡ãƒ•ã‚©ï¼‰ã¨ã—ãŸã€‚
                print(f"{st} Success ({self.frames[i]} frames {w}x{h} at {self.fps[i]:.2f} FPS)")
                self.threads[i].start()
                #print('** ', self.threads) # debug print
            else:
                print(f'{st}Failed to open Cam {s}')
                self.imgs[i] = np.full((self.h, self.w, 3), (128, 128, 128), dtype=np.uint8)

        print('')  # newline

        self.rect = True #np.unique(s, axis=0).shape[0] == 1  # rect inference if all shapes equal

    def update(self, i, cap, stream):
        # Read stream `i` frames in daemon thread
        n, f, read = 0, self.frames[i], 1  # frame number, frame array, inference every 'read' frame
        while cap.isOpened() and n < f and self.flag: # flagã‚‚ãƒ«ãƒ¼ãƒ—ã®æ¡ä»¶ã«åŠ ãˆã¦ã„ã‚‹
            start_t = time.perf_counter()
            n += 1
            #_, self.imgs[i] = cap.read()
            cap.grab()
            if n % read == 0:
                success, im = cap.retrieve()
                if success:
                    self.imgs[i] = im
                else:
                    print('WARNING: Video stream unresponsive, please check your IP camera connection.')
                    self.imgs[i] = np.zeros_like(self.imgs[i])
                    cap.open(stream)  # re-open stream if signal was lost
            end_t = time.perf_counter()
            #print(str(i) + 'ã€€elapse time = {:.3f} Seconds'.format((end_t - start_t))) 
            time.sleep(1 / self.fps[i])  # wait time
        cap.release() # ç„¡é™ãƒ«ãƒ¼ãƒ—ã‹ã‚‰æŠœã‘ãŸã‚‰ã‚«ãƒ¡ãƒ©ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’é–‹æ”¾ã™ã‚‹ã®ã‚’å¿˜ã‚Œãªã„ã“ã¨ï¼

    def __iter__(self):
        self.count = -1
        return self

    def __next__(self):
        self.count += 1
        #if not all(x.isAlive() for x in self.threads) or cv2.waitKey(1) == 27: #ord('q'):  # q to quit
        if cv2.waitKey(1) == 27:  # esc to quit 
            self.flag = False # ç”»åƒå–è¾¼ã®ç„¡é™ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹ãŸã‚ãƒ•ãƒ©ã‚°ã‚’æ›¸ãæ›ãˆã‚‹
            cv2.destroyAllWindows()          
            raise StopIteration

        #h, w, _ = self.imgs[0].shape # ç”»åƒã®ã‚µã‚¤ã‚ºã‚’å–è¾¼ã‚“ã§ãŠã
        # ã“ã“ã§4ã¤ã®ç”»åƒã‚’åˆæˆã™ã‚‹
        if len(self.sources) == 1:
            self.imgs[1] = np.full((self.h, self.w, 3), (128, 128, 128), dtype=np.uint8)
        self.concimg = cv2.hconcat([self.imgs[0], self.imgs[1]])
        if len(self.sources) > 2:
            if len(self.sources) == 3:
                self.imgs[3] = np.full((self.h, self.w, 3), (128, 128, 128), dtype=np.uint8)
            conc2 = cv2.hconcat([self.imgs[2], self.imgs[3]])
            self.concimg = cv2.vconcat([self.concimg, conc2])
            self.concimg = cv2.resize(self.concimg, (800, 600), interpolation = cv2.INTER_AREA)
        else:
            self.concimg = cv2.resize(self.concimg, (800, 300), interpolation = cv2.INTER_AREA)
        self.concimg = cv2.resize(self.concimg, (self.w, self.h), interpolation = cv2.INTER_AREA)
        self.concimg = cv2.vconcat([self.top_obi, self.concimg, self.obi])
        #self.concimg = np.expand_dims(self.concimg, axis=0) # CHW > BCHW 

        img0 = self.concimg.copy()
        # Letterbox
        #img_lb = letterbox(img0)[0] # letterboxé–¢æ•°ã‹ã‚‰è¿”ã£ã¦ããŸç”»åƒéƒ¨åˆ†ã®ã¿
        img_lb = None # 202409ç¾åœ¨letterboxå‡¦ç†ã¯MultiBackendã«ä»»ã›ã‚‹ã®ã§â€¦

        return self.sources, img_lb, img0, self.rbt_flag, self.bad_cam

    def __len__(self):
        return len(self.sources)  # 1E12 frames = 32 streams at 30 FPS for 30 years

class LoadV4Streams:
    # for USB camera  Vertical
    def __init__(self, sources='Vstreams.txt', img_size=640, stride=32, auto=True):
        global flag
        self.img_size = img_size
        self.stride = stride
        self.flag = True # è¤‡æ•°é–‹ã„ãŸã‚«ãƒ¡ãƒ©ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‰ã˜ã‚‹ãŸã‚ã®ãƒ•ãƒ©ã‚°
        self.rbt_flag = False # ãƒ‡ãƒã‚¤ã‚¹ãƒ­ã‚¹ãƒˆãªã©ã§è‡ªå‹•çš„ã«è‡ªåˆ†ã‚’æ­¢ã‚ã‚‹ï¼ˆå†èµ·å‹•è¦å¦ã®ç›®å°ï¼‰ãƒ•ãƒ©ã‚°
        self.bad_cam = "" # ãƒ‡ãƒã‚¤ã‚¹ãƒ­ã‚¹ãƒˆã—ãŸã‚«ãƒ¡ãƒ©ã®ä½ç½®æƒ…å ±ã‚’æ¸¡ã™å¤‰æ•°

        if os.path.isfile(sources):
            with codecs.open(sources, 'r', 'utf-8') as f:
                sources = [x.strip() for x in f.read().strip().splitlines() if len(x.strip()) and x[0] != '#']
        else:
            sources = [sources]

        print(sources)
        n = len(sources)
        self.imgs, self.fps, self.frames, self.threads = [None] * 4, [0] * n, [0] * n, [None] * n
        self.sources = [clean_str(x) for x in sources]  # clean source names for later
        self.auto = auto
        self.w = 640 #int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        self.h = 160 #int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        full_h = 480 # ã‚¯ãƒ­ãƒƒãƒ—ã—ãªã„å ´åˆã®ç¸¦ç”»ç´ æ•°
        self.start_h = int((full_h - self.h) / 2)
        self.obi = np.full((20, self.w, 3), (255, 255, 255), dtype=np.uint8) # å‹•ç”»æƒ…å ±ã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã®å¸¯
        self.top_obi = self.obi.copy()
        self.top_obi[0:20, 0:20] = (0, 0, 255) # ä¸Šã®ã‚ªãƒ“ã¯å·¦ç«¯ã‚’èµ¤ã«ã—ã¦ãƒ—ãƒ­ã‚°ãƒ©ãƒ åœæ­¢ã®ã‚¯ãƒªãƒƒã‚¯ã®ç›®å°ã¨ã™ã‚‹ã€‚
        
        # äºˆã‚èµ¤è‰²ã®ç”»é¢ã‚’ã‚«ãƒ¡ãƒ©ã®æ•°ã ã‘ç”¨æ„ã—ã¦ãŠã
        for i, s in enumerate(sources):  # index, source
            self.imgs[i] = np.full((self.h, self.w, 3), (0, 0, 255), dtype=np.uint8)

        for i, s in enumerate(sources):  # index, source
            # Start thread to read frames from video stream
            st = f'{i + 1}/{n}: {s}... '
            s = eval(s) if s.isnumeric() else s  # i.e. s = '0' local webcam
            cap = cv2.VideoCapture(s + cv2.CAP_DSHOW)
            #assert cap.isOpened(), f'{st}Failed to open {s}'

            self.fps[i] = max(cap.get(cv2.CAP_PROP_FPS) % 100, 0) or 30.0  # 30 FPS fallback
            self.frames[i] = max(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)), 0) or float('inf')  # infinite stream fallback

            if cap.isOpened():
                _, im = cap.read()  # guarantee first frame
                self.imgs[i] = im[self.start_h:(self.start_h + self.h), 0:self.w] # crop
                self.threads[i] = Thread(target=self.update, args=([i, cap, s]), daemon=False)
                # threadsã¯ã€daemon=Trueã§è¤‡æ•°èµ·å‹•ã™ã‚‹ã¨çµ‚äº†æ™‚ã«ã‚«ãƒ¡ãƒ©ã‚’é–‹æ”¾ã—ãªããªã‚‹ã€‚ãã®ãŸã‚daemon=Falseï¼ˆãƒ‡ãƒ•ã‚©ï¼‰ã¨ã—ãŸã€‚
                print(f"{st} Success ({self.frames[i]} frames {self.w}x{self.h} at {self.fps[i]:.2f} FPS)")
                self.threads[i].start()
                #print('** ', self.threads) # debug print
            else:
                print(f'{st}Failed to open Cam {s}')
                self.imgs[i] = np.full((self.h, self.w, 3), (128, 128, 128), dtype=np.uint8)

        print('')  # newline
        
        self.rect = True #np.unique(s, axis=0).shape[0] == 1  # rect inference if all shapes equal

    def update(self, i, cap, stream):
        # Read stream `i` frames in daemon thread
        n, f, read = 0, self.frames[i], 1  # frame number, frame array, inference every 'read' frame
        while cap.isOpened() and n < f and self.flag: # flagã‚‚ãƒ«ãƒ¼ãƒ—ã®æ¡ä»¶ã«åŠ ãˆã¦ã„ã‚‹
            n += 1
            #_, self.imgs[i] = cap.read()
            cap.grab()
            if n % read == 0:
                success, im = cap.retrieve()
                if success:

                    self.imgs[i] = im[self.start_h:(self.start_h + self.h), 0:self.w] # å–ã‚Šè¾¼ã‚“ã ç”»åƒã®é«˜ã•æ–¹å‘ã§ä¸­å¿ƒéƒ¨åˆ†ã ã‘ã‚’ä½¿ã†
                else:
                    print('WARNING: Video stream unresponsive, please check your IP camera connection.')
                    self.imgs[i] = np.zeros_like(self.imgs[i])
                    cap.open(stream)  # re-open stream if signal was lost
            time.sleep(1 / self.fps[i])  # wait time
        cap.release() # ç„¡é™ãƒ«ãƒ¼ãƒ—ã‹ã‚‰æŠœã‘ãŸã‚‰ã‚«ãƒ¡ãƒ©ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’é–‹æ”¾ã™ã‚‹ã®ã‚’å¿˜ã‚Œãªã„ã“ã¨ï¼

    def __iter__(self):
        self.count = -1
        return self

    def __next__(self):
        self.count += 1
        #if not all(x.isAlive() for x in self.threads) or cv2.waitKey(1) == 27: #ord('q'):  # q to quit
        if cv2.waitKey(1) == 27: #ord('q'):  # q to quit 
            self.flag = False # ç”»åƒå–è¾¼ã®ç„¡é™ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹ãŸã‚ãƒ•ãƒ©ã‚°ã‚’æ›¸ãæ›ãˆã‚‹
            cv2.destroyAllWindows()          
            raise StopIteration

        h, w, _ = self.imgs[0].shape # ç”»åƒã®ã‚µã‚¤ã‚ºã‚’å–è¾¼ã‚“ã§ãŠã
        # ã“ã“ã§4ã¤ã®ç”»åƒã‚’åˆæˆã™ã‚‹
        if len(self.sources) == 1:
            self.imgs[1] = np.full((self.h, self.w, 3), (128, 128, 128), dtype=np.uint8)
        self.concimg = cv2.vconcat([self.imgs[0], self.imgs[1]])
        if len(self.sources) > 2:
            if len(self.sources) == 3:
                self.imgs[3] = np.full((self.h, self.w, 3), (128, 128, 128), dtype=np.uint8)
            conc2 = cv2.vconcat([self.imgs[2], self.imgs[3]])
            self.concimg = cv2.vconcat([self.concimg, conc2])
            self.concimg = cv2.resize(self.concimg, (self.w, 4*self.h), interpolation = cv2.INTER_AREA)
        else:
            self.concimg = cv2.resize(self.concimg, (self.w, 2*self.h), interpolation = cv2.INTER_AREA)
        self.obi = np.full((20, self.w, 3), (255, 255, 255), dtype=np.uint8)
        self.concimg = cv2.vconcat([self.top_obi, self.concimg, self.obi])
        #self.concimg = np.expand_dims(self.concimg, axis=0) # CHW > BCHW 

        img0 = self.concimg.copy()
        # Letterbox
        #img_lb = letterbox(img0)[0] # letterboxé–¢æ•°ã‹ã‚‰è¿”ã£ã¦ããŸç”»åƒéƒ¨åˆ†ã®ã¿
        img_lb = None # 202409ç¾åœ¨letterboxå‡¦ç†ã¯MultiBackendã«ä»»ã›ã‚‹ã®ã§â€¦

        return self.sources, img_lb, img0, self.rbt_flag, self.bad_cam

    def __len__(self):
        return len(self.sources)  # 1E12 frames = 32 streams at 30 FPS for 30 years

